{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d45270a-e16e-4397-8ecd-7fee98d7417d",
   "metadata": {},
   "source": [
    "# Preprocessing ChIP-Seq data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324a6f92-2c63-496b-8725-348cdcfb099d",
   "metadata": {},
   "source": [
    "## Convert TagAlign to Bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "809a337b-e68b-4c92-ba07-d977eed78039",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "conda run -n chip_seq bash -c 'for f in data/*.tagAlign; do \\\n",
    "    base=$(basename $f _norm_sorted.tagAlign); \\\n",
    "    bedtools bedtobam \\\n",
    "        -i \"$f\" \\\n",
    "        -g utils/hg19.genome \\\n",
    "        > data/${base}.bam; done'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01602693-01fe-4bca-9788-49a2274b0d66",
   "metadata": {},
   "source": [
    "## Samtools sort and index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a364f9e9-191a-408c-b02c-175fb3fbeb67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 4 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 4 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 18 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 4 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 4 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 4 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 5 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 4 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 5 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 25 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 4 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 5 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 4 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 6 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 4 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 4 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 5 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 4 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 1 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 6 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 1 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 1 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 1 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 5 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 5 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 5 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 7 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 4 files and 1 in-memory blocks...\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "conda run -n chip_seq bash -c 'for f in data/*.bam; do \\\n",
    "    base=$(basename $f .bam); \\\n",
    "    samtools sort \"$f\" -o data/${base}_sorted.bam; done'\n",
    "\n",
    "conda run -n chip_seq bash -c 'for f in data/*_sorted.bam; do \\\n",
    "    base=$(basename $f .bam); \\\n",
    "    samtools index \"$f\" data/${base}.bai; done'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57edd543-976b-4b32-b260-3542e41a78fe",
   "metadata": {},
   "source": [
    "## macs2 call peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4574093f-42d7-4f25-8d3b-95d4b1f36ffe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO  @ Tue, 17 Feb 2026 13:04:53: \n",
      "# Command line: callpeak -t data/GSM2576895_CS13-12383-H3K4me1_sorted.bam -c data/CS13-12383-Input_sorted.bam -f BAM -g hs -B -n CS13-12383-H3K4me1 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS13-12383-H3K4me1\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576895_CS13-12383-H3K4me1_sorted.bam']\n",
      "# control file = ['data/CS13-12383-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 13:04:53: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 13:04:53: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:04:54:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:04:55:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:04:56:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:04:57:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:04:58:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:04:58:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:04:59:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:00:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:01:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:02:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:02:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:03:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:04:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:05:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:06:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:06:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:07:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:08:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:09:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:10:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:10:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:11:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:12:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:13:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:14:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:15:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:15:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:16:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:17:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:18:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:19:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:19:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:20:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:21:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:22:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:23:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:23:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:24:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:25:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:26:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:26:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:27:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:28:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:28: 43322530 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:29: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:29:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:30:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:31:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:32:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:33:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:33:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:34:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:35:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:36:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:37:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:37:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:38:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:39:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:40:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:41:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:41:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:42:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:43:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:44:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:44:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:45:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:46:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:47:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:48:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:48: 24743220 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:48: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:48: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:48: #1  total tags in treatment: 43322530 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:48: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:48: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:49: #1  tags after filtering in treatment: 15736409 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:49: #1  Redundant rate of treatment: 0.64 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:49: #1  total tags in control: 24743220 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:49: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:49: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:49: #1  tags after filtering in control: 23885849 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:49: #1  Redundant rate of control: 0.03 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:49: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:49: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:49: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:51: #2 number of paired peaks: 60448 \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:51: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:52: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:52: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:52: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:52: #2 predicted fragment length is 289 bps \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:52: #2 alternative fragment length(s) may be 289 bps \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:52: #2.2 Generate R script for model : data/CS13-12383-H3K4me1_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:52: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 13:05:52: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 13:07:14: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 13:07:14: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS13-12383-H3K4me1_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 13:07:14: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS13-12383-H3K4me1_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 13:07:14: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 13:07:14: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:40: #4 Write output xls file... data/CS13-12383-H3K4me1_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:41: #4 Write peak in narrowPeak format file... data/CS13-12383-H3K4me1_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:41: #4 Write summits bed file... data/CS13-12383-H3K4me1_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:41: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:41: \n",
      "# Command line: callpeak -t data/GSM2576896_CS13-12690-H3K4me1_sorted.bam -c data/CS13-12690-Input_sorted.bam -f BAM -g hs -B -n CS13-12690-H3K4me1 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS13-12690-H3K4me1\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576896_CS13-12690-H3K4me1_sorted.bam']\n",
      "# control file = ['data/CS13-12690-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:41: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:41: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:42:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:43:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:43:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:44:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:45:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:46:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:47:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:47:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:48:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:49:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:50:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:51:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:51:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:52:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:53:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:54:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:55:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:55:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:56:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:57:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:58:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:59:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:08:59:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:00:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:01:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:02:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:03:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:03:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:04:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:05:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:06:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:07:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:07:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:08:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:09:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:10:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:11:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:11:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:12:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:13:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:14:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:15:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:15:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:16:  44000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:16: 44182401 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:17: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:17:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:18:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:19:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:20:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:21:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:21:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:22:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:23:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:24:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:25:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:25:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:26:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:27:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:28:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:29:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:29:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:30:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:31:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:32:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:33:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:33:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:34:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:35:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:36:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:37:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:37:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:38:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:39:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:40:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:41:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:41:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:42:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:43:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:44:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:45:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:45:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:46:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:47:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:48:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:49:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:50:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:50:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:51:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:52:  44000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:52: 44525557 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:53: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:53: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:53: #1  total tags in treatment: 44182401 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:53: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:53: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:53: #1  tags after filtering in treatment: 38512181 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:53: #1  Redundant rate of treatment: 0.13 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:53: #1  total tags in control: 44525557 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:53: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:53: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:53: #1  tags after filtering in control: 43478680 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:53: #1  Redundant rate of control: 0.02 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:53: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:53: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:53: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:58: #2 number of paired peaks: 70317 \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:58: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:59: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:59: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:59: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:59: #2 predicted fragment length is 237 bps \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:59: #2 alternative fragment length(s) may be 237 bps \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:59: #2.2 Generate R script for model : data/CS13-12690-H3K4me1_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:59: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 13:09:59: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 13:12:34: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 13:12:34: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS13-12690-H3K4me1_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 13:12:34: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS13-12690-H3K4me1_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 13:12:34: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 13:12:34: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:25: #4 Write output xls file... data/CS13-12690-H3K4me1_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:25: #4 Write peak in narrowPeak format file... data/CS13-12690-H3K4me1_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:26: #4 Write summits bed file... data/CS13-12690-H3K4me1_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:26: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:26: \n",
      "# Command line: callpeak -t data/GSM2576897_CS13-12829-H3K4me1_sorted.bam -c data/CS13-12829-Input_sorted.bam -f BAM -g hs -B -n CS13-12829-H3K4me1 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS13-12829-H3K4me1\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576897_CS13-12829-H3K4me1_sorted.bam']\n",
      "# control file = ['data/CS13-12829-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:26: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:26: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:27:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:28:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:28:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:29:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:30:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:31:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:32:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:32:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:33:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:34:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:35:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:35:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:36:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:37:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:38:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:39:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:39:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:40:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:41:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:42:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:42:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:43:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:44:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:45:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:45:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:46:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:47:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:48:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:49:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:49:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:50:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:51:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:52:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:52: 33242804 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:52: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:53:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:54:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:54:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:55:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:56:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:57:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:58:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:58:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:15:59:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:00:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:01:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:02:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:02:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:03:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:04:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:05:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:05:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:06:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:07:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:08:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:08:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:09:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:10:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:11:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:12:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:12:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:13:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:14:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:15:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:16:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:16:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:17:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:18:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:19:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:19:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:20:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:21:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:22:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:23:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:23:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:24:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:25:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:26:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:26:  44000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:27:  45000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:28:  46000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:29:  47000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:30:  48000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:30:  49000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:31:  50000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:31: 50454086 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:32: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:32: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:32: #1  total tags in treatment: 33242804 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:32: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:32: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:32: #1  tags after filtering in treatment: 19611970 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:32: #1  Redundant rate of treatment: 0.41 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:32: #1  total tags in control: 50454086 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:32: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:32: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:32: #1  tags after filtering in control: 43923795 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:32: #1  Redundant rate of control: 0.13 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:32: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:32: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:32: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:36: #2 number of paired peaks: 93903 \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:36: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:36: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:36: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:36: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:36: #2 predicted fragment length is 235 bps \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:36: #2 alternative fragment length(s) may be 235 bps \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:36: #2.2 Generate R script for model : data/CS13-12829-H3K4me1_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:36: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 13:16:36: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 13:18:57: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 13:18:57: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS13-12829-H3K4me1_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 13:18:57: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS13-12829-H3K4me1_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 13:18:57: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 13:18:57: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:16: #4 Write output xls file... data/CS13-12829-H3K4me1_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:17: #4 Write peak in narrowPeak format file... data/CS13-12829-H3K4me1_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:17: #4 Write summits bed file... data/CS13-12829-H3K4me1_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:17: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:17: \n",
      "# Command line: callpeak -t data/GSM2576898_CS13-12830-H3K4me1_sorted.bam -c data/CS13-12830-Input_sorted.bam -f BAM -g hs -B -n CS13-12830-H3K4me1 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS13-12830-H3K4me1\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576898_CS13-12830-H3K4me1_sorted.bam']\n",
      "# control file = ['data/CS13-12830-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:17: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:17: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:18:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:19:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:20:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:21:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:21:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:22:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:23:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:24:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:25:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:25:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:26:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:27:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:28:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:29:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:29:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:30:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:31:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:32:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:33:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:33:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:34:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:35:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:36:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:36:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:37:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:38:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:39:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:40:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:40:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:41:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:42:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:43:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:44:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:44:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:45:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:45: 35215768 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:46: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:46:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:47:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:48:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:49:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:50:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:50:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:51:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:52:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:53:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:54:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:55:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:55:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:56:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:57:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:58:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:58:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:21:59:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:00:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:01:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:02:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:02:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:03:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:04:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:05:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:06:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:06:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:07:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:08:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:09:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:10:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:10:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:11:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:12:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:13:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:14:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:14:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:15:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:16:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:17:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:18:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:18:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:19:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:20:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:21:  44000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:22:  45000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:22:  46000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:23:  47000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:24:  48000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:25:  49000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:26:  50000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:26:  51000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:27: 51833206 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:28: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:28: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:28: #1  total tags in treatment: 35215768 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:28: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:28: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:28: #1  tags after filtering in treatment: 23956731 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:28: #1  Redundant rate of treatment: 0.32 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:28: #1  total tags in control: 51833206 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:28: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:28: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:28: #1  tags after filtering in control: 50159235 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:28: #1  Redundant rate of control: 0.03 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:28: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:28: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:28: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:30: #2 number of paired peaks: 9553 \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:30: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:30: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:30: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:30: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:30: #2 predicted fragment length is 210 bps \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:30: #2 alternative fragment length(s) may be 88,210,230 bps \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:30: #2.2 Generate R script for model : data/CS13-12830-H3K4me1_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:30: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 13:22:30: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 13:25:13: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 13:25:13: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS13-12830-H3K4me1_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 13:25:13: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS13-12830-H3K4me1_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 13:25:13: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 13:25:13: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 13:27:55: #4 Write output xls file... data/CS13-12830-H3K4me1_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 13:27:55: #4 Write peak in narrowPeak format file... data/CS13-12830-H3K4me1_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 13:27:55: #4 Write summits bed file... data/CS13-12830-H3K4me1_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 13:27:55: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 13:27:55: \n",
      "# Command line: callpeak -t data/GSM2576899_CS13-12877-H3K4me1_sorted.bam -c data/CS13-12877-Input_sorted.bam -f BAM -g hs -B -n CS13-12877-H3K4me1 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS13-12877-H3K4me1\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576899_CS13-12877-H3K4me1_sorted.bam']\n",
      "# control file = ['data/CS13-12877-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 13:27:55: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 13:27:55: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:27:56:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:27:57:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:27:58:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:27:58:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:27:59:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:00:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:01:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:02:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:02:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:03:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:04:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:05:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:05:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:06:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:07:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:08:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:09:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:10:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:10:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:11:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:12:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:13:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:14:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:14:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:15:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:16:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:17:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:18:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:18:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:19:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:20:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:21:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:21:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:22:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:23:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:24:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:25:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:25:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:26:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:27:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:28:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:29:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:29:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:30: 43875374 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:31: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:31:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:32:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:33:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:34:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:35:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:35:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:36:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:37:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:38:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:39:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:39:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:40:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:41:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:42:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:43:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:43:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:44:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:45:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:46:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:47:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:47:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:48:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:49:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:50:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:51:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:51:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:52:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:53:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:54:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:54:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:55:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:56:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:57:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:58:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:58:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:59: 35396829 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:59: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:59: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:59: #1  total tags in treatment: 43875374 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:59: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:59: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:59: #1  tags after filtering in treatment: 25278958 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:59: #1  Redundant rate of treatment: 0.42 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:59: #1  total tags in control: 35396829 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:59: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:59: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:59: #1  tags after filtering in control: 30965978 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:59: #1  Redundant rate of control: 0.13 \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:59: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:59: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 13:28:59: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 13:29:03: #2 number of paired peaks: 37405 \n",
      "INFO  @ Tue, 17 Feb 2026 13:29:03: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 13:29:03: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 13:29:03: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 13:29:03: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 13:29:03: #2 predicted fragment length is 216 bps \n",
      "INFO  @ Tue, 17 Feb 2026 13:29:03: #2 alternative fragment length(s) may be 216 bps \n",
      "INFO  @ Tue, 17 Feb 2026 13:29:03: #2.2 Generate R script for model : data/CS13-12877-H3K4me1_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 13:29:03: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 13:29:03: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 13:30:52: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 13:30:52: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS13-12877-H3K4me1_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 13:30:52: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS13-12877-H3K4me1_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 13:30:52: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 13:30:52: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 13:32:47: #4 Write output xls file... data/CS13-12877-H3K4me1_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 13:32:47: #4 Write peak in narrowPeak format file... data/CS13-12877-H3K4me1_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 13:32:48: #4 Write summits bed file... data/CS13-12877-H3K4me1_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 13:32:48: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 13:32:48: \n",
      "# Command line: callpeak -t data/GSM2576900_CS14-12408-H3K4me1_sorted.bam -c data/CS14-12408-Input_sorted.bam -f BAM -g hs -B -n CS14-12408-H3K4me1 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS14-12408-H3K4me1\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576900_CS14-12408-H3K4me1_sorted.bam']\n",
      "# control file = ['data/CS14-12408-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 13:32:48: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 13:32:48: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:32:49:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:32:49:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:32:50:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:32:51:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:32:52:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:32:53:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:32:53:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:32:54:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:32:55:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:32:56:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:32:57:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:32:57:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:32:58:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:32:59:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:00:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:01:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:01:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:02:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:03:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:04:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:05:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:06:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:06:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:07:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:08:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:09:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:10:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:10:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:11:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:12:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:13:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:13:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:14:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:15:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:16:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:17:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:17:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:18:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:19:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:20:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:21:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:21:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:22:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:23:  44000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:24:  45000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:24:  46000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:25:  47000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:26:  48000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:27:  49000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:28:  50000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:28:  51000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:29:  52000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:30:  53000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:31:  54000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:32:  55000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:32: 55714052 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:33: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:34:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:34:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:35:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:36:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:37:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:37:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:38:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:39:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:40:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:41:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:42:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:42:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:43:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:44:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:45:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:46:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:46:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:47:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:48:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:49:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:49:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:50:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:51:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:52:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:53:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:53:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:54:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:55:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:56:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:57:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:57: 30206698 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:57: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:57: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:57: #1  total tags in treatment: 55714052 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:57: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:57: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:57: #1  tags after filtering in treatment: 51093198 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:57: #1  Redundant rate of treatment: 0.08 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:57: #1  total tags in control: 30206698 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:57: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:57: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:57: #1  tags after filtering in control: 29637340 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:57: #1  Redundant rate of control: 0.02 \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:57: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:57: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 13:33:57: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 13:34:02: #2 number of paired peaks: 38631 \n",
      "INFO  @ Tue, 17 Feb 2026 13:34:02: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 13:34:03: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 13:34:03: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 13:34:03: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 13:34:03: #2 predicted fragment length is 213 bps \n",
      "INFO  @ Tue, 17 Feb 2026 13:34:03: #2 alternative fragment length(s) may be 213 bps \n",
      "INFO  @ Tue, 17 Feb 2026 13:34:03: #2.2 Generate R script for model : data/CS14-12408-H3K4me1_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 13:34:03: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 13:34:03: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 13:36:08: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 13:36:08: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS14-12408-H3K4me1_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 13:36:08: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS14-12408-H3K4me1_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 13:36:08: #3   Pileup will be based on sequencing depth in control. \n",
      "INFO  @ Tue, 17 Feb 2026 13:36:08: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:40: #4 Write output xls file... data/CS14-12408-H3K4me1_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:41: #4 Write peak in narrowPeak format file... data/CS14-12408-H3K4me1_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:41: #4 Write summits bed file... data/CS14-12408-H3K4me1_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:41: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:41: \n",
      "# Command line: callpeak -t data/GSM2576901_CS14-12709-H3K4me1_sorted.bam -c data/CS14-12709-Input_sorted.bam -f BAM -g hs -B -n CS14-12709-H3K4me1 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS14-12709-H3K4me1\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576901_CS14-12709-H3K4me1_sorted.bam']\n",
      "# control file = ['data/CS14-12709-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:41: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:41: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:42:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:43:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:44:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:45:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:45:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:46:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:47:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:48:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:49:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:50:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:50:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:51:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:52:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:53:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:54:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:54:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:55:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:56:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:57:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:58:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:59:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:38:59:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:00:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:01:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:02:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:03:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:03:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:04:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:05:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:06:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:07:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:08:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:08:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:09:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:10:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:11:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:12:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:13:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:13:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:14:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:15:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:16:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:17:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:17:  44000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:18:  45000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:19:  46000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:20:  47000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:21:  48000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:22:  49000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:22:  50000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:23:  51000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:24:  52000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:25:  53000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:26:  54000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:26:  55000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:27:  56000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:28:  57000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:29:  58000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:30:  59000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:31:  60000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:31:  61000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:32:  62000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:32: 62277968 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:33: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:34:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:35:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:35:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:36:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:37:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:38:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:39:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:39:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:40:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:41:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:42:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:43:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:44:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:44:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:45:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:46:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:47:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:48:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:48:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:49:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:50:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:51:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:52:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:52:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:53:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:54:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:55:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:56:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:57:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:57:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:58:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:39:59:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:00:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:01:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:02:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:02:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:03:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:04:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:05:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:06:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:06:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:07:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:08:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:09:  44000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:10:  45000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:11:  46000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:11:  47000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:12:  48000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:13:  49000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:14:  50000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:15:  51000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:16:  52000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:16:  53000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:17:  54000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:18:  55000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:19:  56000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:20:  57000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:20:  58000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:21:  59000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:22:  60000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:23:  61000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:24:  62000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:25:  63000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:25:  64000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:26:  65000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:27:  66000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:28:  67000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:29:  68000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:29:  69000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:30:  70000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:31:  71000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:32:  72000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:33:  73000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:34:  74000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:34:  75000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:35:  76000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:36:  77000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:37:  78000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:38:  79000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:39:  80000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:39:  81000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:40:  82000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:41:  83000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:42:  84000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:43:  85000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:43:  86000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:44:  87000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:45:  88000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:46:  89000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:47:  90000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:48:  91000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:48:  92000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:49:  93000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:50:  94000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:51:  95000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:52:  96000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:52:  97000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:53:  98000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:54:  99000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:55:  100000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:56:  101000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:57:  102000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:57:  103000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:58:  104000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:40:59:  105000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:00:  106000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:01:  107000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:01:  108000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:02:  109000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:03:  110000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:04:  111000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:05:  112000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:06:  113000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:06:  114000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:07:  115000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:08:  116000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:09:  117000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:10:  118000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:10:  119000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:11:  120000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:12:  121000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:13:  122000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:14:  123000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:15:  124000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:15:  125000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:16:  126000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:17:  127000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:18:  128000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:19:  129000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:20:  130000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:20:  131000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:21:  132000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:22:  133000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:23:  134000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:24:  135000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:24:  136000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:25:  137000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:26:  138000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:27:  139000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:28:  140000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:29:  141000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:29:  142000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:30:  143000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:31:  144000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:32:  145000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:33:  146000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:33:  147000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:34:  148000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:35:  149000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:36:  150000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:37:  151000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:37:  152000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:38:  153000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:39:  154000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:40:  155000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:41:  156000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:42:  157000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:42:  158000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:43:  159000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:44:  160000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:45:  161000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:46:  162000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:46:  163000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:47:  164000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:48:  165000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:49:  166000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:50:  167000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:51:  168000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:51:  169000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:52:  170000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:53:  171000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:54:  172000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:55:  173000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:56:  174000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:56:  175000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:57:  176000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:58:  177000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:41:59:  178000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:00:  179000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:00:  180000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:01:  181000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:02:  182000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:03:  183000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:04:  184000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:05:  185000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:05:  186000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:06:  187000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:07:  188000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:08:  189000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:09:  190000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:09:  191000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:10:  192000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:11:  193000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:12:  194000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:13:  195000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:14:  196000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:14:  197000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:15:  198000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:16:  199000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:17:  200000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:18:  201000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:19:  202000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:19:  203000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:20:  204000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:21: 204442626 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:23: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:23: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:23: #1  total tags in treatment: 62277968 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:23: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:23: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:23: #1  tags after filtering in treatment: 53432657 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:23: #1  Redundant rate of treatment: 0.14 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:23: #1  total tags in control: 204442626 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:23: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:23: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:23: #1  tags after filtering in control: 194983173 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:23: #1  Redundant rate of control: 0.05 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:23: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:23: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:23: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:28: #2 number of paired peaks: 38298 \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:28: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:29: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:29: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:29: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:29: #2 predicted fragment length is 214 bps \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:29: #2 alternative fragment length(s) may be 214 bps \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:29: #2.2 Generate R script for model : data/CS14-12709-H3K4me1_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:29: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 13:42:29: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 13:51:04: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 13:51:04: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS14-12709-H3K4me1_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 13:51:04: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS14-12709-H3K4me1_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 13:51:04: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 13:51:04: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:00: #4 Write output xls file... data/CS14-12709-H3K4me1_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:01: #4 Write peak in narrowPeak format file... data/CS14-12709-H3K4me1_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:02: #4 Write summits bed file... data/CS14-12709-H3K4me1_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:02: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:02: \n",
      "# Command line: callpeak -t data/GSM2576902_CS14-12913-H3K4me1_sorted.bam -c data/CS14-12913-Input_sorted.bam -f BAM -g hs -B -n CS14-12913-H3K4me1 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS14-12913-H3K4me1\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576902_CS14-12913-H3K4me1_sorted.bam']\n",
      "# control file = ['data/CS14-12913-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:02: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:02: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:03:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:04:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:04:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:05:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:06:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:07:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:08:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:08:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:09:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:10:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:11:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:12:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:13:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:13:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:14:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:15:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:16:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:17:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:17:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:18:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:19:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:20:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:21:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:21:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:22:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:23:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:24:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:25:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:26:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:26:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:27:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:27: 31123975 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:28: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:28:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:29:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:30:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:31:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:32:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:32:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:33:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:34:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:35:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:36:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:36:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:37:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:38:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:39:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:40:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:40:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:41:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:42:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:43:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:44:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:44:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:45:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:46:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:47:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:48:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:48:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:49:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:50:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:51:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:52:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:52:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:53:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:54:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:55:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:56:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:56:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:57:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:58:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:59:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 13:59:59: 39796663 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 14:00:00: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:00:00: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 14:00:00: #1  total tags in treatment: 31123975 \n",
      "INFO  @ Tue, 17 Feb 2026 14:00:00: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:00:00: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 14:00:00: #1  tags after filtering in treatment: 27717246 \n",
      "INFO  @ Tue, 17 Feb 2026 14:00:00: #1  Redundant rate of treatment: 0.11 \n",
      "INFO  @ Tue, 17 Feb 2026 14:00:00: #1  total tags in control: 39796663 \n",
      "INFO  @ Tue, 17 Feb 2026 14:00:00: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:00:00: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 14:00:00: #1  tags after filtering in control: 29950056 \n",
      "INFO  @ Tue, 17 Feb 2026 14:00:00: #1  Redundant rate of control: 0.25 \n",
      "INFO  @ Tue, 17 Feb 2026 14:00:00: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 14:00:00: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 14:00:00: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 14:00:03: #2 number of paired peaks: 29767 \n",
      "INFO  @ Tue, 17 Feb 2026 14:00:03: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 14:00:04: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 14:00:04: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 14:00:04: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 14:00:04: #2 predicted fragment length is 213 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:00:04: #2 alternative fragment length(s) may be 213 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:00:04: #2.2 Generate R script for model : data/CS14-12913-H3K4me1_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 14:00:04: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 14:00:04: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 14:01:49: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 14:01:49: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS14-12913-H3K4me1_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 14:01:49: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS14-12913-H3K4me1_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 14:01:49: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 14:01:49: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 14:03:44: #4 Write output xls file... data/CS14-12913-H3K4me1_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 14:03:44: #4 Write peak in narrowPeak format file... data/CS14-12913-H3K4me1_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 14:03:44: #4 Write summits bed file... data/CS14-12913-H3K4me1_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 14:03:45: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 14:03:45: \n",
      "# Command line: callpeak -t data/GSM2576903_CS15-13000-H3K4me1_sorted.bam -c data/CS15-13000-Input_sorted.bam -f BAM -g hs -B -n CS15-13000-H3K4me1 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS15-13000-H3K4me1\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576903_CS15-13000-H3K4me1_sorted.bam']\n",
      "# control file = ['data/CS15-13000-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 14:03:45: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 14:03:45: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:03:46:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:03:46:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:03:47:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:03:48:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:03:49:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:03:50:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:03:50:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:03:51:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:03:52:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:03:53:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:03:54:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:03:54:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:03:55:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:03:56:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:03:57:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:03:58:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:03:58:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:03:59:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:00:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:01:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:02:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:02:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:03:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:04:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:05:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:06:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:06:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:07:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:08:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:09:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:10:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:11:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:11:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:12:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:12: 34251764 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:13: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:14:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:14:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:15:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:16:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:17:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:18:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:18:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:19:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:20:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:21:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:22:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:22:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:23:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:24:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:25:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:26:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:27:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:27:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:28:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:29:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:30:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:31:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:31:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:32:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:33:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:34:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:35:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:35:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:36:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:37:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:38:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:39:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:40:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:40:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:41:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:41: 35300812 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:42: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:42: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:42: #1  total tags in treatment: 34251764 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:42: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:42: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:42: #1  tags after filtering in treatment: 30400760 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:42: #1  Redundant rate of treatment: 0.11 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:42: #1  total tags in control: 35300812 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:42: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:42: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:42: #1  tags after filtering in control: 29299372 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:42: #1  Redundant rate of control: 0.17 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:42: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:42: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:42: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:45: #2 number of paired peaks: 14281 \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:45: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:45: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:45: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:45: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:45: #2 predicted fragment length is 202 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:45: #2 alternative fragment length(s) may be 202 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:45: #2.2 Generate R script for model : data/CS15-13000-H3K4me1_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:45: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 14:04:45: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 14:06:33: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 14:06:33: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS15-13000-H3K4me1_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 14:06:33: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS15-13000-H3K4me1_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 14:06:33: #3   Pileup will be based on sequencing depth in control. \n",
      "INFO  @ Tue, 17 Feb 2026 14:06:33: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:31: #4 Write output xls file... data/CS15-13000-H3K4me1_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:31: #4 Write peak in narrowPeak format file... data/CS15-13000-H3K4me1_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:31: #4 Write summits bed file... data/CS15-13000-H3K4me1_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:31: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:31: \n",
      "# Command line: callpeak -t data/GSM2576904_CS15-13019-H3K4me1_sorted.bam -c data/CS15-13019-Input_sorted.bam -f BAM -g hs -B -n CS15-13019-H3K4me1 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS15-13019-H3K4me1\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576904_CS15-13019-H3K4me1_sorted.bam']\n",
      "# control file = ['data/CS15-13019-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:31: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:31: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:32:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:32:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:33:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:34:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:35:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:36:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:36:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:37:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:38:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:39:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:40:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:40:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:41:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:42:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:43:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:44:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:44:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:45:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:46:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:47:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:48:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:48:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:49:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:50:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:51:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:52:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:53:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:53:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:54:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:55:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:56:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:56: 31545337 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:56: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:57:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:58:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:08:59:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:00:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:00:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:01:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:02:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:03:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:04:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:04:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:05:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:06:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:07:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:08:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:08:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:09:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:10:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:11:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:12:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:12:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:13:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:14:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:15:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:16:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:16:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:17:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:18:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:19:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:20:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:21:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:21:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:22:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:23:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:24:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:25:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:25:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:26:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:27:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:28:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:29:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:29:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:30:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:31:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:32:  44000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:33:  45000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:33:  46000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:34: 46689657 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:34: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:34: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:34: #1  total tags in treatment: 31545337 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:34: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:34: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:34: #1  tags after filtering in treatment: 29352430 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:34: #1  Redundant rate of treatment: 0.07 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:34: #1  total tags in control: 46689657 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:34: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:34: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:35: #1  tags after filtering in control: 34206377 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:35: #1  Redundant rate of control: 0.27 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:35: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:35: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:35: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:38: #2 number of paired peaks: 34861 \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:38: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:38: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:38: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:38: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:38: #2 predicted fragment length is 207 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:38: #2 alternative fragment length(s) may be 207 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:38: #2.2 Generate R script for model : data/CS15-13019-H3K4me1_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:38: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 14:09:38: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 14:11:35: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 14:11:35: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS15-13019-H3K4me1_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 14:11:35: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS15-13019-H3K4me1_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 14:11:35: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 14:11:35: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 14:13:45: #4 Write output xls file... data/CS15-13019-H3K4me1_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 14:13:46: #4 Write peak in narrowPeak format file... data/CS15-13019-H3K4me1_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 14:13:46: #4 Write summits bed file... data/CS15-13019-H3K4me1_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 14:13:46: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 14:13:46: \n",
      "# Command line: callpeak -t data/GSM2576905_CS15-13128-H3K4me1_sorted.bam -c data/CS15-13128-Input_sorted.bam -f BAM -g hs -B -n CS15-13128-H3K4me1 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS15-13128-H3K4me1\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576905_CS15-13128-H3K4me1_sorted.bam']\n",
      "# control file = ['data/CS15-13128-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 14:13:46: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 14:13:46: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:13:47:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:13:48:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:13:48:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:13:49:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:13:50:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:13:51:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:13:52:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:13:52:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:13:53:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:13:54:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:13:55:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:13:56:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:13:56:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:13:57:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:13:58:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:13:59:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:00:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:00:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:01:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:02:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:03:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:04:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:04:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:05:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:06:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:07:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:07:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:08:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:09:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:10:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:11:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:11:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:12:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:13:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:14:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:14: 35801746 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:15: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:16:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:16:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:17:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:18:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:19:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:19:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:20:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:21:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:22:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:23:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:23:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:24:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:25:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:26:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:27:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:27:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:28:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:29:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:30:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:31:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:31:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:32:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:33:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:34:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:35:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:35:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:36:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:37:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:38:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:39:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:39:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:40:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:41:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:42:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:42:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:43:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:44:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:45:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:46:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:46:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:47:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:48:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:49:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:49: 43838318 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:50: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:50: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:50: #1  total tags in treatment: 35801746 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:50: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:50: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:50: #1  tags after filtering in treatment: 32627728 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:50: #1  Redundant rate of treatment: 0.09 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:50: #1  total tags in control: 43838318 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:50: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:50: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:50: #1  tags after filtering in control: 33710047 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:50: #1  Redundant rate of control: 0.23 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:50: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:50: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:50: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:54: #2 number of paired peaks: 44357 \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:54: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:54: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:54: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:54: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:54: #2 predicted fragment length is 209 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:54: #2 alternative fragment length(s) may be 209 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:54: #2.2 Generate R script for model : data/CS15-13128-H3K4me1_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:54: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 14:14:54: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 14:16:56: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 14:16:56: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS15-13128-H3K4me1_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 14:16:56: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS15-13128-H3K4me1_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 14:16:56: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 14:16:56: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:13: #4 Write output xls file... data/CS15-13128-H3K4me1_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:13: #4 Write peak in narrowPeak format file... data/CS15-13128-H3K4me1_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:14: #4 Write summits bed file... data/CS15-13128-H3K4me1_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:14: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:14: \n",
      "# Command line: callpeak -t data/GSM2576906_CS17-12331-H3K4me1_sorted.bam -c data/CS17-12331-Input_sorted.bam -f BAM -g hs -B -n CS17-12331-H3K4me1 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS17-12331-H3K4me1\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576906_CS17-12331-H3K4me1_sorted.bam']\n",
      "# control file = ['data/CS17-12331-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:14: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:14: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:15:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:15:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:16:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:17:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:18:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:19:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:19:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:20:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:21:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:22:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:22:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:23:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:24:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:25:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:26:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:26:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:27:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:28:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:29:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:29:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:30:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:31:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:32:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:33:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:33:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:34:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:35: 26692576 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:35: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:36:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:37:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:37:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:38:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:39:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:40:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:41:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:41:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:42:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:43:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:44:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:44:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:45:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:46:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:47:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:48:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:48:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:49:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:50:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:51:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:52:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:52:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:53:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:54:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:55:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:56:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:56:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:57:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:58:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:19:59:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:00:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:00:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:00: 32214059 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:01: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:01: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:01: #1  total tags in treatment: 26692576 \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:01: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:01: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:01: #1  tags after filtering in treatment: 24547406 \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:01: #1  Redundant rate of treatment: 0.08 \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:01: #1  total tags in control: 32214059 \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:01: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:01: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:01: #1  tags after filtering in control: 28884394 \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:01: #1  Redundant rate of control: 0.10 \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:01: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:01: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:01: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:05: #2 number of paired peaks: 76685 \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:05: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:05: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:05: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:05: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:05: #2 predicted fragment length is 227 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:05: #2 alternative fragment length(s) may be 227 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:05: #2.2 Generate R script for model : data/CS17-12331-H3K4me1_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:05: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 14:20:05: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 14:21:46: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 14:21:46: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS17-12331-H3K4me1_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 14:21:46: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS17-12331-H3K4me1_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 14:21:46: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 14:21:46: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:35: #4 Write output xls file... data/CS17-12331-H3K4me1_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:36: #4 Write peak in narrowPeak format file... data/CS17-12331-H3K4me1_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:36: #4 Write summits bed file... data/CS17-12331-H3K4me1_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:36: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:36: \n",
      "# Command line: callpeak -t data/GSM2576907_CS17-12341-H3K4me1_sorted.bam -c data/CS17-12341-Input_sorted.bam -f BAM -g hs -B -n CS17-12341-H3K4me1 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS17-12341-H3K4me1\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576907_CS17-12341-H3K4me1_sorted.bam']\n",
      "# control file = ['data/CS17-12341-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:36: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:36: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:37:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:38:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:39:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:40:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:40:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:41:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:42:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:43:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:44:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:44:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:45:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:46:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:47:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:48:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:48:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:49:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:50:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:51:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:52:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:52:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:53:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:54:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:55:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:56:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:56: 24469541 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:56: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:57:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:58:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:59:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:23:59:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:00:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:01:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:02:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:02:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:03:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:04:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:05:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:06:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:06:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:07:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:08:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:09:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:10:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:10:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:11:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:12:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:13:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:14:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:14:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:15:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:16:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:17:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:17:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:18:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:19:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:20:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:21:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:21: 31524997 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:21: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:21: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:21: #1  total tags in treatment: 24469541 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:21: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:21: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:21: #1  tags after filtering in treatment: 20635477 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:21: #1  Redundant rate of treatment: 0.16 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:21: #1  total tags in control: 31524997 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:21: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:21: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:22: #1  tags after filtering in control: 28262820 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:22: #1  Redundant rate of control: 0.10 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:22: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:22: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:22: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:25: #2 number of paired peaks: 74394 \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:25: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:25: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:25: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:25: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:25: #2 predicted fragment length is 242 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:25: #2 alternative fragment length(s) may be 242 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:25: #2.2 Generate R script for model : data/CS17-12341-H3K4me1_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:25: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 14:24:25: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 14:26:01: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 14:26:01: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS17-12341-H3K4me1_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 14:26:01: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS17-12341-H3K4me1_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 14:26:01: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 14:26:01: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 14:27:46: #4 Write output xls file... data/CS17-12341-H3K4me1_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 14:27:47: #4 Write peak in narrowPeak format file... data/CS17-12341-H3K4me1_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 14:27:47: #4 Write summits bed file... data/CS17-12341-H3K4me1_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 14:27:47: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 14:27:47: \n",
      "# Command line: callpeak -t data/GSM2576908_CS17-12611-H3K4me1_sorted.bam -c data/CS17-12611-Input_sorted.bam -f BAM -g hs -B -n CS17-12611-H3K4me1 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS17-12611-H3K4me1\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576908_CS17-12611-H3K4me1_sorted.bam']\n",
      "# control file = ['data/CS17-12611-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 14:27:47: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 14:27:47: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:27:48:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:27:49:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:27:50:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:27:51:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:27:51:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:27:52:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:27:53:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:27:54:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:27:55:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:27:55:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:27:56:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:27:57:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:27:58:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:27:59:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:27:59:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:00:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:01:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:02:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:03:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:03:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:04:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:05:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:06:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:07:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:07:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:07: 25074278 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:08: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:08:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:09:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:10:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:11:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:12:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:12:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:13:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:14:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:15:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:16:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:16:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:17:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:18:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:19:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:20:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:20:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:21:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:22:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:23:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:24:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:24:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:25:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:26:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:27:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:28:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:28:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:29:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:30:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:31:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:32:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:32:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:33: 31831714 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:33: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:33: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:33: #1  total tags in treatment: 25074278 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:33: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:33: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:33: #1  tags after filtering in treatment: 22234693 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:33: #1  Redundant rate of treatment: 0.11 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:33: #1  total tags in control: 31831714 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:33: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:33: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:34: #1  tags after filtering in control: 29886797 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:34: #1  Redundant rate of control: 0.06 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:34: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:34: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:34: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:37: #2 number of paired peaks: 90875 \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:37: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:38: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:38: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:38: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:38: #2 predicted fragment length is 222 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:38: #2 alternative fragment length(s) may be 222 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:38: #2.2 Generate R script for model : data/CS17-12611-H3K4me1_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:38: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 14:28:38: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 14:30:20: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 14:30:20: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS17-12611-H3K4me1_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 14:30:20: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS17-12611-H3K4me1_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 14:30:20: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 14:30:20: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:09: #4 Write output xls file... data/CS17-12611-H3K4me1_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:09: #4 Write peak in narrowPeak format file... data/CS17-12611-H3K4me1_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:10: #4 Write summits bed file... data/CS17-12611-H3K4me1_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:10: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:10: \n",
      "# Command line: callpeak -t data/GSM2576909_CS13-12383-H3K4me2_sorted.bam -c data/CS13-12383-Input_sorted.bam -f BAM -g hs -B -n CS13-12383-H3K4me2 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS13-12383-H3K4me2\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576909_CS13-12383-H3K4me2_sorted.bam']\n",
      "# control file = ['data/CS13-12383-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:10: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:10: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:11:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:11:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:12:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:13:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:14:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:15:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:15:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:16:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:17:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:18:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:19:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:19:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:20:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:21:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:22:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:22:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:23:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:24:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:25:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:26:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:26:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:27:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:28:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:29:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:30:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:30:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:31:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:32:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:33:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:33: 29262038 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:33: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:34:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:35:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:36:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:36:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:37:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:38:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:39:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:39:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:40:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:41:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:42:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:43:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:43:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:44:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:45:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:46:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:47:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:47:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:48:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:49:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:50:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:51:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:51:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:52:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:53: 24743220 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:53: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:53: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:53: #1  total tags in treatment: 29262038 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:53: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:53: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:53: #1  tags after filtering in treatment: 16115381 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:53: #1  Redundant rate of treatment: 0.45 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:53: #1  total tags in control: 24743220 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:53: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:53: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:53: #1  tags after filtering in control: 23885849 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:53: #1  Redundant rate of control: 0.03 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:53: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:53: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:53: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:56: #2 number of paired peaks: 84025 \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:56: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:57: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:57: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:57: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:57: #2 predicted fragment length is 224 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:57: #2 alternative fragment length(s) may be 224 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:57: #2.2 Generate R script for model : data/CS13-12383-H3K4me2_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:57: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 14:32:57: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 14:34:17: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 14:34:17: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS13-12383-H3K4me2_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 14:34:17: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS13-12383-H3K4me2_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 14:34:17: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 14:34:17: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 14:35:46: #4 Write output xls file... data/CS13-12383-H3K4me2_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 14:35:46: #4 Write peak in narrowPeak format file... data/CS13-12383-H3K4me2_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 14:35:46: #4 Write summits bed file... data/CS13-12383-H3K4me2_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 14:35:47: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 14:35:47: \n",
      "# Command line: callpeak -t data/GSM2576910_CS13-12690-H3K4me2_sorted.bam -c data/CS13-12690-Input_sorted.bam -f BAM -g hs -B -n CS13-12690-H3K4me2 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS13-12690-H3K4me2\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576910_CS13-12690-H3K4me2_sorted.bam']\n",
      "# control file = ['data/CS13-12690-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 14:35:47: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 14:35:47: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:35:47:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:35:48:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:35:49:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:35:50:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:35:51:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:35:51:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:35:52:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:35:53:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:35:54:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:35:55:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:35:55:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:35:56:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:35:57:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:35:58:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:35:59:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:35:59:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:00:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:01:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:02:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:02:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:03:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:04:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:05:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:06:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:06:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:07:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:08:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:09:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:10:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:10:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:11: 30494903 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:11: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:12:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:13:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:13:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:14:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:15:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:16:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:17:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:17:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:18:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:19:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:20:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:21:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:21:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:22:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:23:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:24:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:25:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:25:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:26:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:27:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:28:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:29:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:29:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:30:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:31:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:32:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:33:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:33:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:34:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:35:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:36:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:37:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:37:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:38:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:39:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:40:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:40:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:41:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:42:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:43:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:44:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:44:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:45:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:46:  44000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:46: 44525557 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:47: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:47: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:47: #1  total tags in treatment: 30494903 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:47: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:47: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:47: #1  tags after filtering in treatment: 28394138 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:47: #1  Redundant rate of treatment: 0.07 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:47: #1  total tags in control: 44525557 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:47: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:47: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:47: #1  tags after filtering in control: 43478680 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:47: #1  Redundant rate of control: 0.02 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:47: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:47: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:47: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:51: #2 number of paired peaks: 97302 \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:51: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:52: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:52: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:52: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:52: #2 predicted fragment length is 188 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:52: #2 alternative fragment length(s) may be 188 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:52: #2.2 Generate R script for model : data/CS13-12690-H3K4me2_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:52: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 14:36:52: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 14:39:17: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 14:39:17: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS13-12690-H3K4me2_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 14:39:17: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS13-12690-H3K4me2_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 14:39:17: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 14:39:17: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 14:41:48: #4 Write output xls file... data/CS13-12690-H3K4me2_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 14:41:49: #4 Write peak in narrowPeak format file... data/CS13-12690-H3K4me2_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 14:41:49: #4 Write summits bed file... data/CS13-12690-H3K4me2_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 14:41:49: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 14:41:49: \n",
      "# Command line: callpeak -t data/GSM2576911_CS13-12829-H3K4me2_sorted.bam -c data/CS13-12829-Input_sorted.bam -f BAM -g hs -B -n CS13-12829-H3K4me2 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS13-12829-H3K4me2\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576911_CS13-12829-H3K4me2_sorted.bam']\n",
      "# control file = ['data/CS13-12829-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 14:41:49: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 14:41:49: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:41:50:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:41:51:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:41:52:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:41:52:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:41:53:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:41:54:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:41:55:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:41:56:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:41:56:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:41:57:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:41:58:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:41:59:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:00:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:00:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:01:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:02:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:03:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:04:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:04:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:05:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:06:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:07:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:08:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:08:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:09:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:10:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:11:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:12:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:12:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:13:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:14:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:15:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:15:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:16:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:17:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:18:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:19:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:19:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:20:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:21:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:22:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:23:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:23:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:24:  44000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:25:  45000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:26:  46000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:27:  47000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:27:  48000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:28:  49000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:29:  50000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:30:  51000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:31:  52000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:31:  53000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:32: 53363603 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:32: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:33:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:34:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:35:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:35:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:36:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:37:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:38:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:39:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:40:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:40:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:41:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:42:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:43:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:44:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:44:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:45:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:46:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:47:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:48:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:49:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:49:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:50:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:51:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:52:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:53:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:53:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:54:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:55:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:56:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:57:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:57:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:58:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:42:59:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:00:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:01:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:01:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:02:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:03:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:04:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:05:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:05:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:06:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:07:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:08:  44000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:09:  45000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:10:  46000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:10:  47000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:11:  48000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:12:  49000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:13:  50000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:13: 50454086 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:14: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:14: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:14: #1  total tags in treatment: 53363603 \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:14: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:14: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:14: #1  tags after filtering in treatment: 33013109 \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:14: #1  Redundant rate of treatment: 0.38 \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:14: #1  total tags in control: 50454086 \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:14: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:14: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:14: #1  tags after filtering in control: 43923795 \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:14: #1  Redundant rate of control: 0.13 \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:14: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:14: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:14: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:20: #2 number of paired peaks: 118465 \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:20: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:21: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:21: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:21: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:21: #2 predicted fragment length is 171 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:21: #2 alternative fragment length(s) may be 171 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:21: #2.2 Generate R script for model : data/CS13-12829-H3K4me2_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:21: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 14:43:21: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 14:45:51: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 14:45:51: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS13-12829-H3K4me2_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 14:45:51: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS13-12829-H3K4me2_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 14:45:51: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 14:45:51: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:32: #4 Write output xls file... data/CS13-12829-H3K4me2_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:33: #4 Write peak in narrowPeak format file... data/CS13-12829-H3K4me2_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:33: #4 Write summits bed file... data/CS13-12829-H3K4me2_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:33: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:33: \n",
      "# Command line: callpeak -t data/GSM2576912_CS13-12830-H3K4me2_sorted.bam -c data/CS13-12830-Input_sorted.bam -f BAM -g hs -B -n CS13-12830-H3K4me2 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS13-12830-H3K4me2\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576912_CS13-12830-H3K4me2_sorted.bam']\n",
      "# control file = ['data/CS13-12830-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:33: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:33: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:34:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:35:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:35:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:36:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:37:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:38:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:39:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:39:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:40:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:41:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:42:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:42:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:43:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:44:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:45:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:46:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:46:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:47:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:48:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:49:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:50:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:50:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:51:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:52:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:53:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:53:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:54:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:55:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:56:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:57:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:57:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:58:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:48:59:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:00:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:00:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:01:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:02:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:03:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:04:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:04:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:05:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:06:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:07:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:07:  44000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:08:  45000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:09:  46000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:10:  47000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:11:  48000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:11:  49000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:12:  50000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:13:  51000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:14:  52000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:14:  53000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:15:  54000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:16:  55000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:17:  56000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:17: 56000222 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:17: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:18:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:19:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:20:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:20:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:21:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:22:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:23:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:24:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:24:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:25:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:26:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:27:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:28:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:28:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:29:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:30:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:31:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:31:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:32:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:33:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:34:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:35:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:35:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:36:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:37:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:38:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:39:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:39:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:40:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:41:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:42:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:43:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:43:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:44:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:45:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:46:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:47:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:47:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:48:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:49:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:50:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:50:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:51:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:52:  44000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:53:  45000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:54:  46000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:54:  47000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:55:  48000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:56:  49000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:57:  50000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:58:  51000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:58: 51833206 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:59: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:59: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:59: #1  total tags in treatment: 56000222 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:59: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:59: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:59: #1  tags after filtering in treatment: 37304127 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:59: #1  Redundant rate of treatment: 0.33 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:59: #1  total tags in control: 51833206 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:59: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:59: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:59: #1  tags after filtering in control: 50159235 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:59: #1  Redundant rate of control: 0.03 \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:59: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:59: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 14:49:59: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 14:50:05: #2 number of paired peaks: 127553 \n",
      "INFO  @ Tue, 17 Feb 2026 14:50:05: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 14:50:07: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 14:50:07: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 14:50:07: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 14:50:07: #2 predicted fragment length is 170 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:50:07: #2 alternative fragment length(s) may be 170 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:50:07: #2.2 Generate R script for model : data/CS13-12830-H3K4me2_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 14:50:07: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 14:50:07: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 14:52:55: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 14:52:55: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS13-12830-H3K4me2_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 14:52:55: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS13-12830-H3K4me2_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 14:52:55: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 14:52:55: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 14:55:55: #4 Write output xls file... data/CS13-12830-H3K4me2_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 14:55:56: #4 Write peak in narrowPeak format file... data/CS13-12830-H3K4me2_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 14:55:56: #4 Write summits bed file... data/CS13-12830-H3K4me2_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 14:55:57: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 14:55:57: \n",
      "# Command line: callpeak -t data/GSM2576913_CS13-12877-H3K4me2_sorted.bam -c data/CS13-12877-Input_sorted.bam -f BAM -g hs -B -n CS13-12877-H3K4me2 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS13-12877-H3K4me2\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576913_CS13-12877-H3K4me2_sorted.bam']\n",
      "# control file = ['data/CS13-12877-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 14:55:57: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 14:55:57: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:55:58:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:55:58:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:55:59:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:00:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:01:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:01:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:02:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:03:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:04:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:05:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:05:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:06:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:07:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:08:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:09:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:09:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:10:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:11:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:12:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:13:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:13:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:14:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:15:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:16:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:17:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:17:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:18:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:19:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:20:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:20:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:21:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:22:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:23:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:24:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:24:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:25:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:26:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:27:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:28:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:28: 39152853 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:28: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:29:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:30:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:30:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:31:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:32:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:33:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:34:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:34:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:35:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:36:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:37:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:38:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:38:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:39:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:40:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:41:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:42:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:42:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:43:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:44:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:45:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:46:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:46:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:47:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:48:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:49:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:49:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:50:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:51:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:52:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:53:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:53:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:54:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:55:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:56:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:56: 35396829 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:56: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:56: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:56: #1  total tags in treatment: 39152853 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:56: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:56: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:57: #1  tags after filtering in treatment: 26677049 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:57: #1  Redundant rate of treatment: 0.32 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:57: #1  total tags in control: 35396829 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:57: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:57: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:57: #1  tags after filtering in control: 30965978 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:57: #1  Redundant rate of control: 0.13 \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:57: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:57: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 14:56:57: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 14:57:01: #2 number of paired peaks: 93881 \n",
      "INFO  @ Tue, 17 Feb 2026 14:57:01: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 14:57:02: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 14:57:02: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 14:57:02: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 14:57:02: #2 predicted fragment length is 152 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:57:02: #2 alternative fragment length(s) may be 152 bps \n",
      "INFO  @ Tue, 17 Feb 2026 14:57:02: #2.2 Generate R script for model : data/CS13-12877-H3K4me2_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 14:57:02: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 14:57:02: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 14:58:49: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 14:58:49: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS13-12877-H3K4me2_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 14:58:49: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS13-12877-H3K4me2_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 14:58:49: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 14:58:49: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 15:00:55: #4 Write output xls file... data/CS13-12877-H3K4me2_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 15:00:56: #4 Write peak in narrowPeak format file... data/CS13-12877-H3K4me2_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 15:00:56: #4 Write summits bed file... data/CS13-12877-H3K4me2_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 15:00:56: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 15:00:56: \n",
      "# Command line: callpeak -t data/GSM2576914_CS14-12408-H3K4me2_sorted.bam -c data/CS14-12408-Input_sorted.bam -f BAM -g hs -B -n CS14-12408-H3K4me2 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS14-12408-H3K4me2\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576914_CS14-12408-H3K4me2_sorted.bam']\n",
      "# control file = ['data/CS14-12408-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 15:00:56: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 15:00:56: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 15:00:57:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:00:58:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:00:59:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:00:59:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:00:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:01:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:02:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:02:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:03:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:04:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:05:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:06:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:06:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:07:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:08:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:09:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:10:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:10:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:11:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:12:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:13:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:14:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:14:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:15:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:16:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:17:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:18:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:18:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:19:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:20:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:21:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:21:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:22:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:23:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:24:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:25:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:25:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:26:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:27:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:28:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:29:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:29:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:30:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:31:  44000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:32:  45000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:33:  46000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:33:  47000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:34:  48000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:35:  49000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:36:  50000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:37:  51000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:37:  52000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:38:  53000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:39:  54000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:40:  55000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:41:  56000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:41:  57000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:42:  58000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:43:  59000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:44:  60000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:45:  61000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:45:  62000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:46:  63000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:47:  64000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:48:  65000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:48:  66000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:49:  67000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:50:  68000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:51:  69000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:52:  70000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:52:  71000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:53:  72000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:54:  73000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:55:  74000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:56:  75000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:56:  76000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:57:  77000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:58:  78000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:01:59:  79000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:00:  80000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:00:  81000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:01:  82000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:02:  83000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:03:  84000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:04:  85000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:04:  86000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:05:  87000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:06:  88000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:07:  89000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:07:  90000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:08:  91000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:09:  92000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:10:  93000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:11:  94000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:11:  95000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:12:  96000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:13:  97000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:14:  98000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:14:  99000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:15:  100000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:16:  101000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:17:  102000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:18:  103000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:18:  104000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:19:  105000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:20:  106000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:21:  107000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:22:  108000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:22:  109000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:23:  110000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:24:  111000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:25:  112000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:25:  113000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:26:  114000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:27:  115000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:28:  116000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:29:  117000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:29:  118000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:30:  119000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:31:  120000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:32:  121000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:33:  122000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:33:  123000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:34:  124000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:35:  125000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:36:  126000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:36:  127000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:37:  128000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:38:  129000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:39:  130000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:40:  131000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:40:  132000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:41:  133000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:42:  134000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:43:  135000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:44:  136000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:44:  137000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:45:  138000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:46:  139000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:47:  140000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:47:  141000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:48:  142000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:49:  143000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:50:  144000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:51:  145000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:51:  146000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:52:  147000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:53:  148000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:54:  149000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:55:  150000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:55:  151000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:56:  152000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:57:  153000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:58:  154000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:58:  155000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:02:59:  156000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:00:  157000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:01:  158000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:02:  159000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:02:  160000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:03:  161000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:04:  162000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:05:  163000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:06:  164000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:06:  165000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:07:  166000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:08:  167000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:09:  168000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:09:  169000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:10:  170000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:11:  171000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:12:  172000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:13:  173000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:13:  174000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:14:  175000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:15:  176000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:16:  177000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:17:  178000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:17:  179000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:18:  180000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:19:  181000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:20:  182000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:21:  183000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:21:  184000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:22:  185000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:23:  186000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:24:  187000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:24:  188000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:25:  189000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:26:  190000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:27:  191000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:28:  192000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:28:  193000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:29:  194000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:30:  195000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:31:  196000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:32:  197000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:32:  198000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:33:  199000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:34:  200000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:35:  201000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:36:  202000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:36:  203000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:37:  204000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:38:  205000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:39:  206000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:39:  207000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:40:  208000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:41:  209000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:42:  210000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:43:  211000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:43:  212000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:44:  213000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:45:  214000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:46:  215000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:47:  216000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:47:  217000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:48:  218000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:49:  219000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:50:  220000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:51:  221000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:51:  222000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:52:  223000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:53:  224000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:54:  225000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:54:  226000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:55:  227000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:56:  228000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:57:  229000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:58:  230000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:58:  231000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:03:59:  232000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:00:  233000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:01:  234000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:02:  235000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:02:  236000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:03:  237000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:04:  238000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:05:  239000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:05:  240000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:06:  241000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:07:  242000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:08:  243000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:09:  244000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:09:  245000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:10:  246000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:11:  247000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:12:  248000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:13:  249000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:13:  250000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:14:  251000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:15:  252000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:16:  253000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:17:  254000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:17:  255000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:18:  256000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:19:  257000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:20:  258000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:21:  259000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:21:  260000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:22:  261000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:23:  262000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:24:  263000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:25:  264000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:25:  265000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:26:  266000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:27:  267000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:28:  268000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:29:  269000000 \n",
      "INFO  @ Tue, 17 Feb 2026 15:04:29:  270000000 \n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "INFO  @ Tue, 17 Feb 2026 18:37:26: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:27:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:28:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:29:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:30:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:30:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:31:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:32:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:33:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:34:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:34:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:35:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:36:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:37:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:37:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:38:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:39:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:40:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:41:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:41:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:42:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:43:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:44:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:45:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:45:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:46:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:47:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:48:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:49:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:49:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:50:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:51:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:52:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:53:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:53:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:54:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:55:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:56:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:57:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:57:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:58:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:37:59:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:00:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:01:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:01:  44000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:02:  45000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:03:  46000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:04:  47000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:05:  48000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:05:  49000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:06:  50000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:07: 50563463 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:07: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:08:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:09:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:10:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:10:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:11:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:12:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:13:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:13:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:14:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:15:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:16:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:17:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:17:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:18:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:19:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:20:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:21:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:21:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:22:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:23:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:24:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:25:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:26:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:26:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:27:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:28:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:29:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:30:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:30:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:31:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:32:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:33:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:34:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:34:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:35:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:36:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:37:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:37:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:38:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:39: 39796663 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:39: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:39: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:39: #1  total tags in treatment: 50563463 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:39: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:39: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:39: #1  tags after filtering in treatment: 38997319 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:39: #1  Redundant rate of treatment: 0.23 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:39: #1  total tags in control: 39796663 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:39: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:39: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:40: #1  tags after filtering in control: 29950056 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:40: #1  Redundant rate of control: 0.25 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:40: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:40: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:40: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:43: #2 number of paired peaks: 28821 \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:43: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:44: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:44: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:44: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:44: #2 predicted fragment length is 157 bps \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:44: #2 alternative fragment length(s) may be 157 bps \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:44: #2.2 Generate R script for model : data/CS14-12913-H3K27ac_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:44: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 18:38:44: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 18:40:41: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 18:40:41: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS14-12913-H3K27ac_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 18:40:41: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS14-12913-H3K27ac_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 18:40:41: #3   Pileup will be based on sequencing depth in control. \n",
      "INFO  @ Tue, 17 Feb 2026 18:40:41: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 18:42:55: #4 Write output xls file... data/CS14-12913-H3K27ac_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 18:42:55: #4 Write peak in narrowPeak format file... data/CS14-12913-H3K27ac_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 18:42:55: #4 Write summits bed file... data/CS14-12913-H3K27ac_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 18:42:55: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 18:42:55: \n",
      "# Command line: callpeak -t data/GSM2576947_CS15-13000-H3K27ac_sorted.bam -c data/CS15-13000-Input_sorted.bam -f BAM -g hs -B -n CS15-13000-H3K27ac -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS15-13000-H3K27ac\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576947_CS15-13000-H3K27ac_sorted.bam']\n",
      "# control file = ['data/CS15-13000-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 18:42:55: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 18:42:55: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 18:42:56:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:42:57:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:42:58:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:42:58:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:42:59:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:00:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:01:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:02:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:03:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:03:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:04:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:05:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:06:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:07:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:07:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:08:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:09:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:10:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:11:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:11:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:12:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:13:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:14:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:15:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:16:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:16:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:17:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:18:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:19:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:20:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:20:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:21:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:22:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:23:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:24:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:24:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:25:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:26:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:27:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:28:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:28:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:29:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:30:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:31: 43642891 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:31: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:32:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:33:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:34:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:34:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:35:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:36:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:37:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:38:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:39:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:39:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:40:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:41:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:42:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:43:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:43:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:44:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:45:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:46:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:47:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:47:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:48:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:49:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:50:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:51:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:52:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:52:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:53:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:54:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:55:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:56:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:56:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:57:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:58:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:43:59:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:44:00:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:44:00: 35300812 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 18:44:00: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 18:44:00: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 18:44:00: #1  total tags in treatment: 43642891 \n",
      "INFO  @ Tue, 17 Feb 2026 18:44:00: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 18:44:00: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 18:44:00: #1  tags after filtering in treatment: 38773643 \n",
      "INFO  @ Tue, 17 Feb 2026 18:44:00: #1  Redundant rate of treatment: 0.11 \n",
      "INFO  @ Tue, 17 Feb 2026 18:44:00: #1  total tags in control: 35300812 \n",
      "INFO  @ Tue, 17 Feb 2026 18:44:00: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 18:44:00: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 18:44:01: #1  tags after filtering in control: 29299372 \n",
      "INFO  @ Tue, 17 Feb 2026 18:44:01: #1  Redundant rate of control: 0.17 \n",
      "INFO  @ Tue, 17 Feb 2026 18:44:01: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 18:44:01: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 18:44:01: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 18:44:04: #2 number of paired peaks: 17415 \n",
      "INFO  @ Tue, 17 Feb 2026 18:44:04: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 18:44:05: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 18:44:05: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 18:44:05: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 18:44:05: #2 predicted fragment length is 155 bps \n",
      "INFO  @ Tue, 17 Feb 2026 18:44:05: #2 alternative fragment length(s) may be 155 bps \n",
      "INFO  @ Tue, 17 Feb 2026 18:44:05: #2.2 Generate R script for model : data/CS15-13000-H3K27ac_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 18:44:05: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 18:44:05: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 18:45:59: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 18:45:59: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS15-13000-H3K27ac_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 18:45:59: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS15-13000-H3K27ac_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 18:45:59: #3   Pileup will be based on sequencing depth in control. \n",
      "INFO  @ Tue, 17 Feb 2026 18:45:59: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:14: #4 Write output xls file... data/CS15-13000-H3K27ac_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:14: #4 Write peak in narrowPeak format file... data/CS15-13000-H3K27ac_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:14: #4 Write summits bed file... data/CS15-13000-H3K27ac_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:14: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:15: \n",
      "# Command line: callpeak -t data/GSM2576948_CS15-13019-H3K27ac_sorted.bam -c data/CS15-13019-Input_sorted.bam -f BAM -g hs -B -n CS15-13019-H3K27ac -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS15-13019-H3K27ac\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576948_CS15-13019-H3K27ac_sorted.bam']\n",
      "# control file = ['data/CS15-13019-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:15: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:15: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:16:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:16:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:17:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:18:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:19:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:20:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:20:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:21:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:22:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:23:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:24:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:24:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:25:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:26:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:27:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:28:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:28:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:29:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:30:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:31:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:32:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:32:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:33:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:34:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:35:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:36:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:36:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:37:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:38:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:39: 29887033 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:39: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:40:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:41:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:41:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:42:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:43:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:44:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:45:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:46:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:46:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:47:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:48:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:49:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:50:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:50:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:51:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:52:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:53:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:54:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:54:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:55:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:56:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:57:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:58:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:58:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:48:59:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:00:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:01:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:02:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:02:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:03:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:04:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:05:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:06:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:06:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:07:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:08:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:09:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:10:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:11:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:11:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:12:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:13:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:14:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:15:  44000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:15:  45000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:16:  46000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:17: 46689657 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:17: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:17: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:17: #1  total tags in treatment: 29887033 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:17: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:17: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:17: #1  tags after filtering in treatment: 27422085 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:17: #1  Redundant rate of treatment: 0.08 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:17: #1  total tags in control: 46689657 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:17: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:17: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:17: #1  tags after filtering in control: 34206377 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:17: #1  Redundant rate of control: 0.27 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:17: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:17: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:17: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:20: #2 number of paired peaks: 32677 \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:20: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:21: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:21: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:21: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:21: #2 predicted fragment length is 163 bps \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:21: #2 alternative fragment length(s) may be 163 bps \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:21: #2.2 Generate R script for model : data/CS15-13019-H3K27ac_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:21: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 18:49:21: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 18:51:20: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 18:51:20: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS15-13019-H3K27ac_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 18:51:20: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS15-13019-H3K27ac_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 18:51:20: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 18:51:20: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:30: #4 Write output xls file... data/CS15-13019-H3K27ac_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:30: #4 Write peak in narrowPeak format file... data/CS15-13019-H3K27ac_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:30: #4 Write summits bed file... data/CS15-13019-H3K27ac_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:30: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:30: \n",
      "# Command line: callpeak -t data/GSM2576949_CS15-13128-H3K27ac_sorted.bam -c data/CS15-13128-Input_sorted.bam -f BAM -g hs -B -n CS15-13128-H3K27ac -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS15-13128-H3K27ac\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576949_CS15-13128-H3K27ac_sorted.bam']\n",
      "# control file = ['data/CS15-13128-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:30: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:30: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:31:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:32:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:33:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:33:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:34:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:35:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:36:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:37:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:38:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:38:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:39:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:40:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:41:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:42:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:42:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:43:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:44:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:45:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:46:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:46:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:47:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:48:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:49:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:50:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:51:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:51:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:52:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:53:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:54:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:55:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:55:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:56:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:57:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:58:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:53:59:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:00:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:00:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:01:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:02:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:03:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:04:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:04:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:05:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:06:  44000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:07:  45000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:08:  46000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:08:  47000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:09:  48000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:10:  49000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:11:  50000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:12:  51000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:12:  52000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:13:  53000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:14:  54000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:15:  55000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:16:  56000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:16:  57000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:16: 57141658 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:17: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:18:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:19:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:19:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:20:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:21:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:22:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:23:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:23:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:24:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:25:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:26:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:27:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:28:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:28:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:29:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:30:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:31:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:32:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:32:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:33:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:34:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:35:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:36:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:36:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:37:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:38:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:39:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:40:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:41:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:41:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:42:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:43:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:44:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:45:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:45:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:46:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:47:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:48:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:49:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:50:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:51:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:51:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:52:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:53: 43838318 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:53: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:53: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:53: #1  total tags in treatment: 57141658 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:53: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:53: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:53: #1  tags after filtering in treatment: 46114310 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:53: #1  Redundant rate of treatment: 0.19 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:53: #1  total tags in control: 43838318 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:53: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:53: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:54: #1  tags after filtering in control: 33710047 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:54: #1  Redundant rate of control: 0.23 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:54: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:54: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:54: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:58: #2 number of paired peaks: 37967 \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:58: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:59: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:59: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:59: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:59: #2 predicted fragment length is 157 bps \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:59: #2 alternative fragment length(s) may be 157 bps \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:59: #2.2 Generate R script for model : data/CS15-13128-H3K27ac_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:59: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 18:54:59: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 18:57:14: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 18:57:14: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS15-13128-H3K27ac_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 18:57:14: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS15-13128-H3K27ac_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 18:57:14: #3   Pileup will be based on sequencing depth in control. \n",
      "INFO  @ Tue, 17 Feb 2026 18:57:14: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 18:59:54: #4 Write output xls file... data/CS15-13128-H3K27ac_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 18:59:54: #4 Write peak in narrowPeak format file... data/CS15-13128-H3K27ac_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 18:59:54: #4 Write summits bed file... data/CS15-13128-H3K27ac_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 18:59:54: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 18:59:54: \n",
      "# Command line: callpeak -t data/GSM2576950_CS17-12191-H3K27ac_sorted.bam -c data/CS17-12191-Input_sorted.bam -f BAM -g hs -B -n CS17-12191-H3K27ac -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS17-12191-H3K27ac\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576950_CS17-12191-H3K27ac_sorted.bam']\n",
      "# control file = ['data/CS17-12191-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 18:59:54: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 18:59:54: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 18:59:55:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:59:56:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:59:57:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:59:58:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:59:58:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 18:59:59:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:00:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:01:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:02:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:02:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:03:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:04:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:05:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:06:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:06:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:07:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:08:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:09:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:09:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:10:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:11:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:12:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:13:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:13:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:14:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:15:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:16:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:16:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:17:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:18:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:19:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:20:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:20:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:21:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:22:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:23:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:23:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:24:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:25:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:26:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:27:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:27:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:28:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:29:  44000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:30:  45000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:31: 45980130 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:31: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:32:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:33:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:33:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:34:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:35:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:36:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:37:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:37:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:38:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:39:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:40:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:41:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:41:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:42:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:43:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:44:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:45:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:45:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:46:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:47:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:48:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:48:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:49:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:50:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:51:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:52:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:52:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:53:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:54:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:55:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:56:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:56:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:57:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:58:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:59:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:00:59:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:01:00: 36294528 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 19:01:00: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:01:00: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 19:01:00: #1  total tags in treatment: 45980130 \n",
      "INFO  @ Tue, 17 Feb 2026 19:01:00: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:01:00: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 19:01:00: #1  tags after filtering in treatment: 44717293 \n",
      "INFO  @ Tue, 17 Feb 2026 19:01:00: #1  Redundant rate of treatment: 0.03 \n",
      "INFO  @ Tue, 17 Feb 2026 19:01:00: #1  total tags in control: 36294528 \n",
      "INFO  @ Tue, 17 Feb 2026 19:01:00: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:01:00: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 19:01:00: #1  tags after filtering in control: 35776210 \n",
      "INFO  @ Tue, 17 Feb 2026 19:01:00: #1  Redundant rate of control: 0.01 \n",
      "INFO  @ Tue, 17 Feb 2026 19:01:00: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 19:01:00: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 19:01:00: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 19:01:05: #2 number of paired peaks: 44050 \n",
      "INFO  @ Tue, 17 Feb 2026 19:01:05: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 19:01:06: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 19:01:06: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 19:01:06: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 19:01:06: #2 predicted fragment length is 155 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:01:06: #2 alternative fragment length(s) may be 155 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:01:06: #2.2 Generate R script for model : data/CS17-12191-H3K27ac_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 19:01:06: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 19:01:06: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 19:03:22: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 19:03:22: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS17-12191-H3K27ac_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 19:03:22: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS17-12191-H3K27ac_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 19:03:22: #3   Pileup will be based on sequencing depth in control. \n",
      "INFO  @ Tue, 17 Feb 2026 19:03:22: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:01: #4 Write output xls file... data/CS17-12191-H3K27ac_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:02: #4 Write peak in narrowPeak format file... data/CS17-12191-H3K27ac_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:02: #4 Write summits bed file... data/CS17-12191-H3K27ac_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:02: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:02: \n",
      "# Command line: callpeak -t data/GSM2576951_CS17-12331-H3K27ac_sorted.bam -c data/CS17-12331-Input_sorted.bam -f BAM -g hs -B -n CS17-12331-H3K27ac -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS17-12331-H3K27ac\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576951_CS17-12331-H3K27ac_sorted.bam']\n",
      "# control file = ['data/CS17-12331-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:02: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:02: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:03:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:04:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:05:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:06:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:06:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:07:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:08:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:09:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:10:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:11:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:12:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:12:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:13:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:14:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:15:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:16:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:16:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:17:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:18:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:19:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:20:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:20:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:21:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:22:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:23:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:24:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:24:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:25:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:26:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:27:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:28:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:28:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:29:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:30:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:31:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:31:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:32:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:33:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:34: 38765556 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:34: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:35:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:36:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:37:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:37:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:38:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:39:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:40:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:41:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:41:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:42:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:43:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:44:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:45:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:45:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:46:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:47:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:48:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:49:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:49:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:50:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:51:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:52:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:53:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:53:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:54:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:55:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:56:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:56:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:57:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:58:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:06:59:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:07:00:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:07:00: 32214059 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 19:07:00: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:07:00: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 19:07:00: #1  total tags in treatment: 38765556 \n",
      "INFO  @ Tue, 17 Feb 2026 19:07:00: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:07:00: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 19:07:00: #1  tags after filtering in treatment: 34518781 \n",
      "INFO  @ Tue, 17 Feb 2026 19:07:00: #1  Redundant rate of treatment: 0.11 \n",
      "INFO  @ Tue, 17 Feb 2026 19:07:00: #1  total tags in control: 32214059 \n",
      "INFO  @ Tue, 17 Feb 2026 19:07:00: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:07:00: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 19:07:00: #1  tags after filtering in control: 28884394 \n",
      "INFO  @ Tue, 17 Feb 2026 19:07:00: #1  Redundant rate of control: 0.10 \n",
      "INFO  @ Tue, 17 Feb 2026 19:07:00: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 19:07:00: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 19:07:00: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 19:07:05: #2 number of paired peaks: 68919 \n",
      "INFO  @ Tue, 17 Feb 2026 19:07:05: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 19:07:06: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 19:07:06: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 19:07:06: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 19:07:06: #2 predicted fragment length is 180 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:07:06: #2 alternative fragment length(s) may be 180 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:07:06: #2.2 Generate R script for model : data/CS17-12331-H3K27ac_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 19:07:06: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 19:07:06: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 19:08:58: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 19:08:58: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS17-12331-H3K27ac_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 19:08:58: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS17-12331-H3K27ac_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 19:08:58: #3   Pileup will be based on sequencing depth in control. \n",
      "INFO  @ Tue, 17 Feb 2026 19:08:58: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:09: #4 Write output xls file... data/CS17-12331-H3K27ac_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:09: #4 Write peak in narrowPeak format file... data/CS17-12331-H3K27ac_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:09: #4 Write summits bed file... data/CS17-12331-H3K27ac_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:10: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:10: \n",
      "# Command line: callpeak -t data/GSM2576952_CS17-12341-H3K27ac_sorted.bam -c data/CS17-12341-Input_sorted.bam -f BAM -g hs -B -n CS17-12341-H3K27ac -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS17-12341-H3K27ac\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576952_CS17-12341-H3K27ac_sorted.bam']\n",
      "# control file = ['data/CS17-12341-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:10: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:10: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:11:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:11:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:12:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:13:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:14:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:15:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:16:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:16:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:17:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:18:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:19:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:20:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:21:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:21:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:22:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:23:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:24:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:25:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:25:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:26:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:27:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:28:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:29:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:30:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:30:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:31:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:32:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:33:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:34:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:35:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:35:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:36:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:37:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:38:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:39:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:40: 35945813 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:40: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:41:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:41:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:42:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:43:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:44:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:45:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:46:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:46:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:47:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:48:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:49:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:50:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:50:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:51:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:52:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:53:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:54:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:55:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:55:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:56:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:57:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:58:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:59:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:11:59:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:00:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:01:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:02:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:03:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:03:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:04:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:05:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:05: 31524997 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:06: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:06: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:06: #1  total tags in treatment: 35945813 \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:06: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:06: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:06: #1  tags after filtering in treatment: 32755487 \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:06: #1  Redundant rate of treatment: 0.09 \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:06: #1  total tags in control: 31524997 \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:06: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:06: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:06: #1  tags after filtering in control: 28262820 \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:06: #1  Redundant rate of control: 0.10 \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:06: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:06: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:06: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:10: #2 number of paired peaks: 72187 \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:10: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:11: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:11: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:11: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:11: #2 predicted fragment length is 189 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:11: #2 alternative fragment length(s) may be 189 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:11: #2.2 Generate R script for model : data/CS17-12341-H3K27ac_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:11: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 19:12:11: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 19:13:57: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 19:13:57: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS17-12341-H3K27ac_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 19:13:57: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS17-12341-H3K27ac_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 19:13:57: #3   Pileup will be based on sequencing depth in control. \n",
      "INFO  @ Tue, 17 Feb 2026 19:13:57: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:05: #4 Write output xls file... data/CS17-12341-H3K27ac_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:05: #4 Write peak in narrowPeak format file... data/CS17-12341-H3K27ac_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:05: #4 Write summits bed file... data/CS17-12341-H3K27ac_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:05: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:06: \n",
      "# Command line: callpeak -t data/GSM2576953_CS17-12611-H3K27ac_sorted.bam -c data/CS17-12611-Input_sorted.bam -f BAM -g hs -B -n CS17-12611-H3K27ac -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS17-12611-H3K27ac\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576953_CS17-12611-H3K27ac_sorted.bam']\n",
      "# control file = ['data/CS17-12611-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:06: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:06: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:06:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:07:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:08:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:09:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:10:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:11:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:11:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:12:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:13:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:14:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:15:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:15:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:16:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:17:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:18:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:19:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:19:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:20:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:21:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:22:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:23:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:23:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:24:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:25:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:26:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:27:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:27:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:28:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:29: 28651176 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:29: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:30:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:31:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:32:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:32:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:33:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:34:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:35:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:36:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:36:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:37:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:38:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:39:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:40:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:40:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:41:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:42:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:43:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:44:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:44:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:45:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:46:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:47:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:48:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:48:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:49:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:50:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:51:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:52:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:52:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:53:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:54:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:55: 31831714 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:55: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:55: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:55: #1  total tags in treatment: 28651176 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:55: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:55: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:55: #1  tags after filtering in treatment: 27666814 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:55: #1  Redundant rate of treatment: 0.03 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:55: #1  total tags in control: 31831714 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:55: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:55: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:55: #1  tags after filtering in control: 29886797 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:55: #1  Redundant rate of control: 0.06 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:55: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:55: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:55: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:59: #2 number of paired peaks: 68522 \n",
      "INFO  @ Tue, 17 Feb 2026 19:16:59: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 19:17:00: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 19:17:00: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 19:17:00: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 19:17:00: #2 predicted fragment length is 192 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:17:00: #2 alternative fragment length(s) may be 192 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:17:00: #2.2 Generate R script for model : data/CS17-12611-H3K27ac_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 19:17:00: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 19:17:00: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 19:18:49: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 19:18:49: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS17-12611-H3K27ac_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 19:18:49: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS17-12611-H3K27ac_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 19:18:49: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 19:18:49: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 19:20:47: #4 Write output xls file... data/CS17-12611-H3K27ac_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 19:20:48: #4 Write peak in narrowPeak format file... data/CS17-12611-H3K27ac_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 19:20:48: #4 Write summits bed file... data/CS17-12611-H3K27ac_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 19:20:48: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 19:20:48: \n",
      "# Command line: callpeak -t data/GSM2576954_CS20-12104-H3K27ac_sorted.bam -c data/CS20-12104-Input_sorted.bam -f BAM -g hs -B -n CS20-12104-H3K27ac -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS20-12104-H3K27ac\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576954_CS20-12104-H3K27ac_sorted.bam']\n",
      "# control file = ['data/CS20-12104-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 19:20:48: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 19:20:48: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:20:49:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:20:50:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:20:51:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:20:52:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:20:52:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:20:53:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:20:54:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:20:55:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:20:56:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:20:56:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:20:57:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:20:58:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:20:59:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:20:59:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:00:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:01:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:02:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:03:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:03:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:04:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:05:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:06:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:07:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:07:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:08:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:09:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:10:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:10:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:11:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:12:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:13:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:14:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:14:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:15:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:16:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:17:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:18:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:18:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:19:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:20:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:21:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:21:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:22: 42260009 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:22: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:23:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:24:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:25:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:25:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:26:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:27:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:28:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:29:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:29:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:30:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:31:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:32:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:32:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:33:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:34:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:35:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:36:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:36:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:37:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:38:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:39:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:40:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:40:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:41:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:42:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:43:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:43:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:44:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:45:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:46:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:47:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:47:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:48:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:49:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:50:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:51:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:51:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:52:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:53:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:54:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:54:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:55:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:56:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:57:  44000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:58:  45000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:58:  46000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:21:59:  47000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:22:00: 47561475 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 19:22:00: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:22:00: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 19:22:00: #1  total tags in treatment: 42260009 \n",
      "INFO  @ Tue, 17 Feb 2026 19:22:00: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:22:00: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 19:22:00: #1  tags after filtering in treatment: 40514598 \n",
      "INFO  @ Tue, 17 Feb 2026 19:22:00: #1  Redundant rate of treatment: 0.04 \n",
      "INFO  @ Tue, 17 Feb 2026 19:22:00: #1  total tags in control: 47561475 \n",
      "INFO  @ Tue, 17 Feb 2026 19:22:00: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:22:00: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 19:22:00: #1  tags after filtering in control: 46842772 \n",
      "INFO  @ Tue, 17 Feb 2026 19:22:00: #1  Redundant rate of control: 0.02 \n",
      "INFO  @ Tue, 17 Feb 2026 19:22:00: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 19:22:00: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 19:22:00: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 19:22:05: #2 number of paired peaks: 56896 \n",
      "INFO  @ Tue, 17 Feb 2026 19:22:05: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 19:22:06: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 19:22:06: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 19:22:06: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 19:22:06: #2 predicted fragment length is 138 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:22:06: #2 alternative fragment length(s) may be 138 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:22:06: #2.2 Generate R script for model : data/CS20-12104-H3K27ac_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 19:22:06: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 19:22:06: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 19:24:49: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 19:24:49: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS20-12104-H3K27ac_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 19:24:49: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS20-12104-H3K27ac_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 19:24:49: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 19:24:49: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 19:27:45: #4 Write output xls file... data/CS20-12104-H3K27ac_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 19:27:45: #4 Write peak in narrowPeak format file... data/CS20-12104-H3K27ac_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 19:27:46: #4 Write summits bed file... data/CS20-12104-H3K27ac_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 19:27:46: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 19:27:46: \n",
      "# Command line: callpeak -t data/GSM2576956_CS13-12383-H3K27me3_sorted.bam -c data/CS13-12383-Input_sorted.bam -f BAM -g hs -B -n CS13-12383-H3K27me3 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS13-12383-H3K27me3\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576956_CS13-12383-H3K27me3_sorted.bam']\n",
      "# control file = ['data/CS13-12383-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 19:27:46: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 19:27:46: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:27:47:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:27:48:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:27:48:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:27:49:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:27:50:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:27:51:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:27:52:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:27:52:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:27:53:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:27:54:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:27:55:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:27:55:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:27:56:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:27:57:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:27:58:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:27:59:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:27:59:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:00:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:01:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:02:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:02:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:03: 21655944 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:03: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:04:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:05:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:05:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:06:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:07:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:08:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:09:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:10:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:10:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:11:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:12:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:13:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:14:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:14:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:15:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:16:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:17:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:18:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:18:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:19:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:20:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:21:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:22:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:22:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:23: 24743220 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:23: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:23: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:23: #1  total tags in treatment: 21655944 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:23: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:23: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:23: #1  tags after filtering in treatment: 4307775 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:23: #1  Redundant rate of treatment: 0.80 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:23: #1  total tags in control: 24743220 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:23: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:23: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:23: #1  tags after filtering in control: 23885849 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:23: #1  Redundant rate of control: 0.03 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:23: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:23: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:23: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:27: #2 number of paired peaks: 65968 \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:27: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:27: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:27: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:27: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:27: #2 predicted fragment length is 298 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:27: #2 alternative fragment length(s) may be 298 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:27: #2.2 Generate R script for model : data/CS13-12383-H3K27me3_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:27: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 19:28:27: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 19:29:36: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 19:29:36: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS13-12383-H3K27me3_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 19:29:36: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS13-12383-H3K27me3_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 19:29:36: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 19:29:36: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 19:30:48: #4 Write output xls file... data/CS13-12383-H3K27me3_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 19:30:48: #4 Write peak in narrowPeak format file... data/CS13-12383-H3K27me3_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 19:30:48: #4 Write summits bed file... data/CS13-12383-H3K27me3_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 19:30:48: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 19:30:48: \n",
      "# Command line: callpeak -t data/GSM2576957_CS13-12690-H3K27me3_sorted.bam -c data/CS13-12690-Input_sorted.bam -f BAM -g hs -B -n CS13-12690-H3K27me3 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS13-12690-H3K27me3\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576957_CS13-12690-H3K27me3_sorted.bam']\n",
      "# control file = ['data/CS13-12690-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 19:30:48: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 19:30:48: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:30:49:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:30:50:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:30:51:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:30:51:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:30:52:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:30:53:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:30:54:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:30:54:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:30:55:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:30:56:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:30:57:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:30:58:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:30:59:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:30:59:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:00:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:01:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:02:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:03:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:03:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:04:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:05:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:06:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:06:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:07:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:08:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:09:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:10:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:10:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:11:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:12:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:13:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:13:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:14:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:15:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:16:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:16:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:17: 36289595 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:17: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:18:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:19:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:20:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:21:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:21:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:22:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:23:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:24:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:25:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:25:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:26:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:27:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:28:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:28:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:29:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:30:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:31:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:32:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:32:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:33:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:34:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:35:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:36:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:36:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:37:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:38:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:39:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:39:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:40:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:41:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:42:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:43:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:43:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:44:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:45:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:46:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:47:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:47:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:48:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:49:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:50:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:51:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:51:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:52:  44000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:53: 44525557 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:53: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:53: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:53: #1  total tags in treatment: 36289595 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:53: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:53: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:53: #1  tags after filtering in treatment: 8404327 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:53: #1  Redundant rate of treatment: 0.77 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:53: #1  total tags in control: 44525557 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:53: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:53: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:53: #1  tags after filtering in control: 43478680 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:53: #1  Redundant rate of control: 0.02 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:53: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:53: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:53: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:55: #2 number of paired peaks: 35740 \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:55: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:55: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:55: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:55: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:55: #2 predicted fragment length is 296 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:55: #2 alternative fragment length(s) may be 296 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:55: #2.2 Generate R script for model : data/CS13-12690-H3K27me3_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:55: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 19:31:55: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 19:34:04: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 19:34:04: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS13-12690-H3K27me3_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 19:34:04: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS13-12690-H3K27me3_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 19:34:04: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 19:34:04: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:07: #4 Write output xls file... data/CS13-12690-H3K27me3_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:07: #4 Write peak in narrowPeak format file... data/CS13-12690-H3K27me3_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:07: #4 Write summits bed file... data/CS13-12690-H3K27me3_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:07: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:07: \n",
      "# Command line: callpeak -t data/GSM2576958_CS13-12829-H3K27me3_sorted.bam -c data/CS13-12829-Input_sorted.bam -f BAM -g hs -B -n CS13-12829-H3K27me3 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS13-12829-H3K27me3\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576958_CS13-12829-H3K27me3_sorted.bam']\n",
      "# control file = ['data/CS13-12829-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:07: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:07: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:08:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:09:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:10:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:11:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:12:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:12:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:13:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:14:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:15:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:15:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:16:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:17:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:18:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:19:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:19:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:20:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:21:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:22:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:23:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:23:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:24:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:25:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:26:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:26:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:27:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:28:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:29:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:30:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:30:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:31:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:32:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:33:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:34:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:34:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:35:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:36:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:37:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:37:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:38:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:39:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:40:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:41:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:41: 42302541 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:41: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:42:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:43:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:44:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:44:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:45:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:46:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:47:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:48:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:48:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:49:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:50:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:51:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:52:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:52:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:53:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:54:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:55:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:56:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:56:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:57:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:58:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:59:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:36:59:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:00:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:01:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:02:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:03:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:03:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:04:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:05:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:06:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:07:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:07:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:08:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:09:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:10:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:11:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:11:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:12:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:13:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:14:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:15:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:15:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:16:  44000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:17:  45000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:18:  46000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:19:  47000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:19:  48000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:20:  49000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:21:  50000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:21: 50454086 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:22: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:22: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:22: #1  total tags in treatment: 42302541 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:22: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:22: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:22: #1  tags after filtering in treatment: 23347545 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:22: #1  Redundant rate of treatment: 0.45 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:22: #1  total tags in control: 50454086 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:22: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:22: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:22: #1  tags after filtering in control: 43923795 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:22: #1  Redundant rate of control: 0.13 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:22: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:22: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:22: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:24: #2 number of paired peaks: 6372 \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:24: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:24: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:24: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:24: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:24: #2 predicted fragment length is 75 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:24: #2 alternative fragment length(s) may be 75,221,275 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:24: #2.2 Generate R script for model : data/CS13-12829-H3K27me3_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:24: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 19:37:24: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 19:39:45: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 19:39:45: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS13-12829-H3K27me3_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 19:39:45: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS13-12829-H3K27me3_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 19:39:45: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 19:39:45: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:17: #4 Write output xls file... data/CS13-12829-H3K27me3_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:17: #4 Write peak in narrowPeak format file... data/CS13-12829-H3K27me3_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:17: #4 Write summits bed file... data/CS13-12829-H3K27me3_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:17: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:18: \n",
      "# Command line: callpeak -t data/GSM2576959_CS13-12830-H3K27me3_sorted.bam -c data/CS13-12830-Input_sorted.bam -f BAM -g hs -B -n CS13-12830-H3K27me3 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS13-12830-H3K27me3\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576959_CS13-12830-H3K27me3_sorted.bam']\n",
      "# control file = ['data/CS13-12830-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:18: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:18: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:18:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:19:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:20:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:21:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:22:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:22:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:23:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:24:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:25:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:26:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:27:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:28:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:28:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:29:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:30:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:31:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:32:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:32:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:33:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:34:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:35:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:36:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:36:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:37:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:38:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:39:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:39: 26924224 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:40: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:41:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:42:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:42:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:43:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:44:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:45:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:46:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:46:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:47:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:48:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:49:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:50:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:50:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:51:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:52:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:53:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:54:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:54:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:55:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:56:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:57:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:58:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:58:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:42:59:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:00:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:01:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:02:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:03:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:03:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:04:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:05:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:06:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:07:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:07:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:08:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:09:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:10:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:11:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:11:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:12:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:13:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:14:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:15:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:16:  44000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:16:  45000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:17:  46000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:18:  47000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:19:  48000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:20:  49000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:21:  50000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:21:  51000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:22: 51833206 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:23: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:23: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:23: #1  total tags in treatment: 26924224 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:23: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:23: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:23: #1  tags after filtering in treatment: 4835123 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:23: #1  Redundant rate of treatment: 0.82 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:23: #1  total tags in control: 51833206 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:23: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:23: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:23: #1  tags after filtering in control: 50159235 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:23: #1  Redundant rate of control: 0.03 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:23: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:23: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:23: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:24: #2 number of paired peaks: 22067 \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:24: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:24: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:24: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:24: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:24: #2 predicted fragment length is 295 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:24: #2 alternative fragment length(s) may be 295 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:24: #2.2 Generate R script for model : data/CS13-12830-H3K27me3_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:24: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 19:43:24: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 19:45:45: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 19:45:45: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS13-12830-H3K27me3_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 19:45:45: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS13-12830-H3K27me3_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 19:45:45: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 19:45:45: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 19:47:58: #4 Write output xls file... data/CS13-12830-H3K27me3_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 19:47:58: #4 Write peak in narrowPeak format file... data/CS13-12830-H3K27me3_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 19:47:58: #4 Write summits bed file... data/CS13-12830-H3K27me3_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 19:47:58: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 19:47:58: \n",
      "# Command line: callpeak -t data/GSM2576960_CS13-12877-H3K27me3_sorted.bam -c data/CS13-12877-Input_sorted.bam -f BAM -g hs -B -n CS13-12877-H3K27me3 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS13-12877-H3K27me3\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576960_CS13-12877-H3K27me3_sorted.bam']\n",
      "# control file = ['data/CS13-12877-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 19:47:58: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 19:47:58: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:47:59:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:00:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:01:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:01:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:02:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:03:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:04:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:05:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:05:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:06:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:07:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:08:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:09:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:09:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:10:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:11:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:12:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:12:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:13:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:14:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:15:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:16:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:17:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:17:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:18:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:19:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:20:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:21:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:21:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:22:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:23:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:24:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:24: 32857420 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:25: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:25:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:26:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:27:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:28:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:29:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:30:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:30:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:31:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:32:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:33:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:34:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:34:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:35:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:36:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:37:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:38:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:39:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:39:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:40:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:41:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:42:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:43:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:43:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:44:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:45:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:46:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:47:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:48:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:48:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:49:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:50:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:51:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:52:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:52:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:53:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:54: 35396829 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:54: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:54: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:54: #1  total tags in treatment: 32857420 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:54: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:54: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:54: #1  tags after filtering in treatment: 9866652 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:54: #1  Redundant rate of treatment: 0.70 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:54: #1  total tags in control: 35396829 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:54: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:54: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:54: #1  tags after filtering in control: 30965978 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:54: #1  Redundant rate of control: 0.13 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:54: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:54: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:54: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:56: #2 number of paired peaks: 10881 \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:56: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:56: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:56: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:56: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:56: #2 predicted fragment length is 294 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:56: #2 alternative fragment length(s) may be 75,294 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:56: #2.2 Generate R script for model : data/CS13-12877-H3K27me3_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:56: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 19:48:56: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 19:50:33: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 19:50:33: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS13-12877-H3K27me3_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 19:50:33: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS13-12877-H3K27me3_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 19:50:33: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 19:50:33: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:12: #4 Write output xls file... data/CS13-12877-H3K27me3_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:12: #4 Write peak in narrowPeak format file... data/CS13-12877-H3K27me3_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:12: #4 Write summits bed file... data/CS13-12877-H3K27me3_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:12: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:12: \n",
      "# Command line: callpeak -t data/GSM2576961_CS14-12408-H3K27me3_sorted.bam -c data/CS14-12408-Input_sorted.bam -f BAM -g hs -B -n CS14-12408-H3K27me3 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS14-12408-H3K27me3\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576961_CS14-12408-H3K27me3_sorted.bam']\n",
      "# control file = ['data/CS14-12408-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:12: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:12: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:13:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:13:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:14:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:15:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:16:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:16:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:17:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:18:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:19:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:20:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:20:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:21:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:22:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:23:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:24:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:24:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:25:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:26:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:27:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:27:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:28:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:29:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:30:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:30:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:31:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:32:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:33:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:33:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:34:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:35:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:36:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:36:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:37:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:38:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:39:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:40:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:40:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:41:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:42:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:43:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:43:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:44:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:45:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:46:  44000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:46:  45000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:47:  46000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:48:  47000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:49:  48000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:50:  49000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:50:  50000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:51:  51000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:52:  52000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:53:  53000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:53:  54000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:54:  55000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:55:  56000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:56:  57000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:56:  58000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:57:  59000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:58:  60000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:59:  61000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:52:59:  62000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:00:  63000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:01:  64000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:02:  65000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:02:  66000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:03:  67000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:04:  68000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:05:  69000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:06:  70000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:06:  71000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:07:  72000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:08:  73000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:09:  74000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:09:  75000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:10:  76000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:10: 76284922 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:11: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:12:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:13:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:13:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:14:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:15:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:16:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:17:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:17:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:18:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:19:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:20:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:21:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:21:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:22:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:23:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:24:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:25:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:25:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:26:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:27:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:28:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:29:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:29:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:30:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:31:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:32:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:33:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:34:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:34:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:35:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:35: 30206698 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:36: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:36: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:36: #1  total tags in treatment: 76284922 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:36: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:36: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:36: #1  tags after filtering in treatment: 7212332 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:36: #1  Redundant rate of treatment: 0.91 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:36: #1  total tags in control: 30206698 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:36: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:36: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:36: #1  tags after filtering in control: 29637340 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:36: #1  Redundant rate of control: 0.02 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:36: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:36: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:36: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:38: #2 number of paired peaks: 28565 \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:38: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:38: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:38: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:38: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:38: #2 predicted fragment length is 295 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:38: #2 alternative fragment length(s) may be 295 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:38: #2.2 Generate R script for model : data/CS14-12408-H3K27me3_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:38: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 19:53:38: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 19:55:07: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 19:55:07: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS14-12408-H3K27me3_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 19:55:07: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS14-12408-H3K27me3_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 19:55:07: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 19:55:07: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:34: #4 Write output xls file... data/CS14-12408-H3K27me3_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:35: #4 Write peak in narrowPeak format file... data/CS14-12408-H3K27me3_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:35: #4 Write summits bed file... data/CS14-12408-H3K27me3_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:35: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:35: \n",
      "# Command line: callpeak -t data/GSM2576962_CS14-12709-H3K27me3_sorted.bam -c data/CS14-12709-Input_sorted.bam -f BAM -g hs -B -n CS14-12709-H3K27me3 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS14-12709-H3K27me3\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576962_CS14-12709-H3K27me3_sorted.bam']\n",
      "# control file = ['data/CS14-12709-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:35: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:35: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:36:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:36:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:37:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:38:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:39:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:39:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:40:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:41:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:42:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:43:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:44:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:44:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:45:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:46:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:47:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:48:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:48:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:49:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:50:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:50: 19258920 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:50: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:51:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:52:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:53:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:54:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:54:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:55:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:56:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:57:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:58:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:58:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:56:59:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:00:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:01:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:02:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:02:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:03:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:04:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:05:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:06:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:06:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:07:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:08:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:09:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:09:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:10:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:11:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:12:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:13:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:14:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:14:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:15:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:16:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:17:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:18:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:18:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:19:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:20:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:21:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:22:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:22:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:23:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:24:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:25:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:25:  44000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:26:  45000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:27:  46000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:28:  47000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:29:  48000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:29:  49000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:30:  50000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:31:  51000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:32:  52000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:33:  53000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:33:  54000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:34:  55000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:35:  56000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:36:  57000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:37:  58000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:37:  59000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:38:  60000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:39:  61000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:40:  62000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:41:  63000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:41:  64000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:42:  65000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:43:  66000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:44:  67000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:45:  68000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:45:  69000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:46:  70000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:47:  71000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:48:  72000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:49:  73000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:49:  74000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:50:  75000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:51:  76000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:52:  77000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:53:  78000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:53:  79000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:54:  80000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:55:  81000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:56:  82000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:57:  83000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:57:  84000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:58:  85000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:57:59:  86000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:00:  87000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:01:  88000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:01:  89000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:02:  90000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:03:  91000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:04:  92000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:05:  93000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:05:  94000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:06:  95000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:07:  96000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:08:  97000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:09:  98000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:09:  99000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:10:  100000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:11:  101000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:12:  102000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:12:  103000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:13:  104000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:14:  105000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:15:  106000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:16:  107000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:17:  108000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:17:  109000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:18:  110000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:19:  111000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:20:  112000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:21:  113000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:21:  114000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:22:  115000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:23:  116000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:24:  117000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:25:  118000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:25:  119000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:26:  120000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:27:  121000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:28:  122000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:29:  123000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:29:  124000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:30:  125000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:31:  126000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:32:  127000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:33:  128000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:33:  129000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:34:  130000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:35:  131000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:36:  132000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:37:  133000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:37:  134000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:38:  135000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:39:  136000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:40:  137000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:41:  138000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:41:  139000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:42:  140000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:43:  141000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:44:  142000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:45:  143000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:45:  144000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:46:  145000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:47:  146000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:48:  147000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:49:  148000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:49:  149000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:50:  150000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:51:  151000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:52:  152000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:52:  153000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:53:  154000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:54:  155000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:55:  156000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:56:  157000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:56:  158000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:57:  159000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:58:  160000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:58:59:  161000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:00:  162000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:00:  163000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:01:  164000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:02:  165000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:03:  166000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:04:  167000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:04:  168000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:05:  169000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:06:  170000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:07:  171000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:07:  172000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:08:  173000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:09:  174000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:10:  175000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:11:  176000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:11:  177000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:12:  178000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:13:  179000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:14:  180000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:15:  181000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:15:  182000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:16:  183000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:17:  184000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:18:  185000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:19:  186000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:19:  187000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:20:  188000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:21:  189000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:22:  190000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:23:  191000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:23:  192000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:24:  193000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:25:  194000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:26:  195000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:27:  196000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:27:  197000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:28:  198000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:29:  199000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:30:  200000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:31:  201000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:31:  202000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:32:  203000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:33:  204000000 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:33: 204442626 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:35: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:35: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:35: #1  total tags in treatment: 19258920 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:35: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:35: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:35: #1  tags after filtering in treatment: 5933936 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:35: #1  Redundant rate of treatment: 0.69 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:35: #1  total tags in control: 204442626 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:35: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:35: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:36: #1  tags after filtering in control: 194983173 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:36: #1  Redundant rate of control: 0.05 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:36: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:36: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:36: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:38: #2 number of paired peaks: 42839 \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:38: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:38: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:38: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:38: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:38: #2 predicted fragment length is 297 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:38: #2 alternative fragment length(s) may be 297 bps \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:38: #2.2 Generate R script for model : data/CS14-12709-H3K27me3_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:38: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 19:59:38: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 20:07:32: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 20:07:32: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS14-12709-H3K27me3_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 20:07:32: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS14-12709-H3K27me3_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 20:07:32: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 20:07:32: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:26: #4 Write output xls file... data/CS14-12709-H3K27me3_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:26: #4 Write peak in narrowPeak format file... data/CS14-12709-H3K27me3_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:26: #4 Write summits bed file... data/CS14-12709-H3K27me3_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:26: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:27: \n",
      "# Command line: callpeak -t data/GSM2576963_CS14-12913-H3K27me3_sorted.bam -c data/CS14-12913-Input_sorted.bam -f BAM -g hs -B -n CS14-12913-H3K27me3 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS14-12913-H3K27me3\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576963_CS14-12913-H3K27me3_sorted.bam']\n",
      "# control file = ['data/CS14-12913-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:27: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:27: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:28:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:28:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:29:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:30:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:31:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:32:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:33:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:33:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:34:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:35:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:36:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:37:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:37:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:38:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:39:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:40:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:41:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:41:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:42:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:43:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:44:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:45:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:45:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:46:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:47:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:48:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:49:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:49:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:50:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:51:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:52:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:53:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:53: 32820104 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:54: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:54:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:55:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:56:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:57:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:58:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:58:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:14:59:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:00:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:01:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:02:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:03:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:03:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:04:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:05:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:06:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:07:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:07:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:08:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:09:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:10:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:11:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:11:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:12:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:13:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:14:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:15:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:16:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:16:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:17:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:18:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:19:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:20:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:20:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:21:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:22:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:23:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:24:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:24:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:25:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:26: 39796663 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:26: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:26: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:26: #1  total tags in treatment: 32820104 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:26: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:26: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:26: #1  tags after filtering in treatment: 15702514 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:26: #1  Redundant rate of treatment: 0.52 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:26: #1  total tags in control: 39796663 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:26: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:26: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:27: #1  tags after filtering in control: 29950056 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:27: #1  Redundant rate of control: 0.25 \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:27: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:27: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:27: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:28: #2 number of paired peaks: 776 \n",
      "WARNING @ Tue, 17 Feb 2026 20:15:28: Fewer paired peaks (776) than 1000! Model may not be build well! Lower your MFOLD parameter may erase this warning. Now I will use 776 pairs to build model! \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:28: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:28: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:28: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:28: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:28: #2 predicted fragment length is 69 bps \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:28: #2 alternative fragment length(s) may be 69,231,273,463,513,579 bps \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:28: #2.2 Generate R script for model : data/CS14-12913-H3K27me3_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:28: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 20:15:28: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 20:17:05: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 20:17:05: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS14-12913-H3K27me3_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 20:17:05: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS14-12913-H3K27me3_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 20:17:05: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 20:17:05: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 20:18:58: #4 Write output xls file... data/CS14-12913-H3K27me3_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 20:18:58: #4 Write peak in narrowPeak format file... data/CS14-12913-H3K27me3_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 20:18:58: #4 Write summits bed file... data/CS14-12913-H3K27me3_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 20:18:58: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 20:18:58: \n",
      "# Command line: callpeak -t data/GSM2576964_CS15-13000-H3K27me3_sorted.bam -c data/CS15-13000-Input_sorted.bam -f BAM -g hs -B -n CS15-13000-H3K27me3 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS15-13000-H3K27me3\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576964_CS15-13000-H3K27me3_sorted.bam']\n",
      "# control file = ['data/CS15-13000-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 20:18:58: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 20:18:58: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 20:18:59:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:00:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:00:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:01:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:02:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:03:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:04:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:04:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:05:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:06:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:07:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:08:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:08:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:09:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:10:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:11:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:12:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:12:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:13:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:14:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:14: 20615839 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:15: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:15:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:16:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:17:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:18:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:19:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:19:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:20:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:21:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:22:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:23:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:23:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:24:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:25:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:26:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:27:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:27:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:28:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:29:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:30:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:31:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:31:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:32:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:33:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:34:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:35:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:35:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:36:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:37:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:38:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:39:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:40:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:40:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:41:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:42:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:43:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:43: 35300812 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:43: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:43: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:43: #1  total tags in treatment: 20615839 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:43: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:43: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:43: #1  tags after filtering in treatment: 10876625 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:43: #1  Redundant rate of treatment: 0.47 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:43: #1  total tags in control: 35300812 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:43: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:43: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:43: #1  tags after filtering in control: 29299372 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:43: #1  Redundant rate of control: 0.17 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:43: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:43: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:43: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:45: #2 number of paired peaks: 1386 \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:45: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:45: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:45: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:45: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:45: #2 predicted fragment length is 71 bps \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:45: #2 alternative fragment length(s) may be 71,206,229,260,403,477,544 bps \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:45: #2.2 Generate R script for model : data/CS15-13000-H3K27me3_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:45: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 20:19:45: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 20:21:16: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 20:21:16: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS15-13000-H3K27me3_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 20:21:16: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS15-13000-H3K27me3_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 20:21:16: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 20:21:16: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:01: #4 Write output xls file... data/CS15-13000-H3K27me3_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:01: #4 Write peak in narrowPeak format file... data/CS15-13000-H3K27me3_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:01: #4 Write summits bed file... data/CS15-13000-H3K27me3_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:01: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:01: \n",
      "# Command line: callpeak -t data/GSM2576965_CS15-13019-H3K27me3_sorted.bam -c data/CS15-13019-Input_sorted.bam -f BAM -g hs -B -n CS15-13019-H3K27me3 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS15-13019-H3K27me3\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576965_CS15-13019-H3K27me3_sorted.bam']\n",
      "# control file = ['data/CS15-13019-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:01: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:01: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:01:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:02:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:03:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:04:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:05:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:05:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:06:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:07:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:08:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:08:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:09:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:10:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:11:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:12:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:12:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:13:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:14:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:15:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:15:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:16:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:17:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:18:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:19:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:19:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:20:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:21:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:22:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:22: 27901965 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:23: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:23:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:24:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:25:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:26:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:27:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:28:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:28:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:29:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:30:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:31:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:32:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:32:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:33:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:34:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:35:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:35:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:36:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:37:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:38:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:39:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:39:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:40:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:41:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:42:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:43:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:43:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:44:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:45:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:46:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:47:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:47:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:48:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:49:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:50:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:51:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:51:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:52:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:53:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:54:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:54:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:55:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:56:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:57:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:58:  44000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:58:  45000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:23:59:  46000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:24:00: 46689657 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 20:24:00: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 20:24:00: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 20:24:00: #1  total tags in treatment: 27901965 \n",
      "INFO  @ Tue, 17 Feb 2026 20:24:00: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 20:24:00: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 20:24:00: #1  tags after filtering in treatment: 5455366 \n",
      "INFO  @ Tue, 17 Feb 2026 20:24:00: #1  Redundant rate of treatment: 0.80 \n",
      "INFO  @ Tue, 17 Feb 2026 20:24:00: #1  total tags in control: 46689657 \n",
      "INFO  @ Tue, 17 Feb 2026 20:24:00: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 20:24:00: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 20:24:00: #1  tags after filtering in control: 34206377 \n",
      "INFO  @ Tue, 17 Feb 2026 20:24:00: #1  Redundant rate of control: 0.27 \n",
      "INFO  @ Tue, 17 Feb 2026 20:24:00: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 20:24:00: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 20:24:00: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 20:24:02: #2 number of paired peaks: 13522 \n",
      "INFO  @ Tue, 17 Feb 2026 20:24:02: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 20:24:02: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 20:24:02: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 20:24:02: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 20:24:02: #2 predicted fragment length is 291 bps \n",
      "INFO  @ Tue, 17 Feb 2026 20:24:02: #2 alternative fragment length(s) may be 291 bps \n",
      "INFO  @ Tue, 17 Feb 2026 20:24:02: #2.2 Generate R script for model : data/CS15-13019-H3K27me3_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 20:24:03: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 20:24:03: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 20:25:42: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 20:25:42: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS15-13019-H3K27me3_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 20:25:42: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS15-13019-H3K27me3_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 20:25:42: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 20:25:42: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:21: #4 Write output xls file... data/CS15-13019-H3K27me3_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:21: #4 Write peak in narrowPeak format file... data/CS15-13019-H3K27me3_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:21: #4 Write summits bed file... data/CS15-13019-H3K27me3_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:21: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:21: \n",
      "# Command line: callpeak -t data/GSM2576966_CS15-13128-H3K27me3_sorted.bam -c data/CS15-13128-Input_sorted.bam -f BAM -g hs -B -n CS15-13128-H3K27me3 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS15-13128-H3K27me3\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576966_CS15-13128-H3K27me3_sorted.bam']\n",
      "# control file = ['data/CS15-13128-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:21: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:21: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:22:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:23:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:24:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:24:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:25:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:26:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:27:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:28:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:28:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:29:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:30:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:31:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:31:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:32:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:33:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:34:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:34:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:35:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:36:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:37:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:38:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:38:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:39:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:40:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:41:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:42:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:42:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:43:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:44:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:45:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:45:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:46:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:47:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:48:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:48: 34752402 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:49: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:50:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:50:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:51:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:52:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:53:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:54:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:54:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:55:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:56:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:57:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:58:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:58:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:27:59:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:00:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:01:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:02:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:02:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:03:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:04:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:05:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:06:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:06:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:07:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:08:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:09:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:10:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:10:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:11:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:12:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:13:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:13:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:14:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:15:  33000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:16:  34000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:17:  35000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:17:  36000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:18:  37000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:19:  38000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:20:  39000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:21:  40000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:21:  41000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:22:  42000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:23:  43000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:24: 43838318 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:24: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:24: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:24: #1  total tags in treatment: 34752402 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:24: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:24: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:24: #1  tags after filtering in treatment: 10926057 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:24: #1  Redundant rate of treatment: 0.69 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:24: #1  total tags in control: 43838318 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:24: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:24: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:24: #1  tags after filtering in control: 33710047 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:24: #1  Redundant rate of control: 0.23 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:24: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:24: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:24: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:26: #2 number of paired peaks: 2228 \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:26: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:26: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:26: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:26: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:26: #2 predicted fragment length is 71 bps \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:26: #2 alternative fragment length(s) may be 71,237,265,450,528 bps \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:26: #2.2 Generate R script for model : data/CS15-13128-H3K27me3_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:26: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 20:28:26: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 20:30:11: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 20:30:11: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS15-13128-H3K27me3_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 20:30:11: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS15-13128-H3K27me3_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 20:30:11: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 20:30:11: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:06: #4 Write output xls file... data/CS15-13128-H3K27me3_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:06: #4 Write peak in narrowPeak format file... data/CS15-13128-H3K27me3_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:06: #4 Write summits bed file... data/CS15-13128-H3K27me3_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:06: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:06: \n",
      "# Command line: callpeak -t data/GSM2576967_CS17-12331-H3K27me3_sorted.bam -c data/CS17-12331-Input_sorted.bam -f BAM -g hs -B -n CS17-12331-H3K27me3 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS17-12331-H3K27me3\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576967_CS17-12331-H3K27me3_sorted.bam']\n",
      "# control file = ['data/CS17-12331-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:06: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:06: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:07:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:07:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:08:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:09:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:10:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:11:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:11:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:12:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:13:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:14:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:15:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:15:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:16:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:17:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:18:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:18:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:19:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:20:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:21:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:22:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:22:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:23:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:24:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:25:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:25:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:26:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:27:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:28:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:29:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:29:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:30:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:31:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:32: 32686202 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:32: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:33:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:33:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:34:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:35:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:36:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:37:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:38:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:39:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:39:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:40:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:41:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:42:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:43:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:43:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:44:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:45:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:46:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:46:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:47:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:48:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:49:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:50:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:50:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:51:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:52:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:53:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:54:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:54:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:55:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:56:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:57:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:57:  32000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:58: 32214059 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:58: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:58: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:58: #1  total tags in treatment: 32686202 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:58: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:58: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:58: #1  tags after filtering in treatment: 23623004 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:58: #1  Redundant rate of treatment: 0.28 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:58: #1  total tags in control: 32214059 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:58: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:58: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:58: #1  tags after filtering in control: 28884394 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:58: #1  Redundant rate of control: 0.10 \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:58: #1 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:58: #2 Build Peak Model... \n",
      "INFO  @ Tue, 17 Feb 2026 20:32:58: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 20:33:01: #2 number of paired peaks: 36364 \n",
      "INFO  @ Tue, 17 Feb 2026 20:33:01: start model_add_line... \n",
      "INFO  @ Tue, 17 Feb 2026 20:33:01: start X-correlation... \n",
      "INFO  @ Tue, 17 Feb 2026 20:33:01: end of X-cor \n",
      "INFO  @ Tue, 17 Feb 2026 20:33:01: #2 finished! \n",
      "INFO  @ Tue, 17 Feb 2026 20:33:01: #2 predicted fragment length is 256 bps \n",
      "INFO  @ Tue, 17 Feb 2026 20:33:01: #2 alternative fragment length(s) may be 256 bps \n",
      "INFO  @ Tue, 17 Feb 2026 20:33:01: #2.2 Generate R script for model : data/CS17-12331-H3K27me3_model.r \n",
      "INFO  @ Tue, 17 Feb 2026 20:33:01: #3 Call peaks... \n",
      "INFO  @ Tue, 17 Feb 2026 20:33:01: #3 Pre-compute pvalue-qvalue table... \n",
      "INFO  @ Tue, 17 Feb 2026 20:34:48: #3 In the peak calling step, the following will be performed simultaneously: \n",
      "INFO  @ Tue, 17 Feb 2026 20:34:48: #3   Write bedGraph files for treatment pileup (after scaling if necessary)... CS17-12331-H3K27me3_treat_pileup.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 20:34:48: #3   Write bedGraph files for control lambda (after scaling if necessary)... CS17-12331-H3K27me3_control_lambda.bdg \n",
      "INFO  @ Tue, 17 Feb 2026 20:34:48: #3   Pileup will be based on sequencing depth in treatment. \n",
      "INFO  @ Tue, 17 Feb 2026 20:34:48: #3 Call peaks for each chromosome... \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:38: #4 Write output xls file... data/CS17-12331-H3K27me3_peaks.xls \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:38: #4 Write peak in narrowPeak format file... data/CS17-12331-H3K27me3_peaks.narrowPeak \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:38: #4 Write summits bed file... data/CS17-12331-H3K27me3_summits.bed \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:38: Done! \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:38: \n",
      "# Command line: callpeak -t data/GSM2576968_CS17-12341-H3K27me3_sorted.bam -c data/CS17-12341-Input_sorted.bam -f BAM -g hs -B -n CS17-12341-H3K27me3 -q 0.01 --outdir data/\n",
      "# ARGUMENTS LIST:\n",
      "# name = CS17-12341-H3K27me3\n",
      "# format = BAM\n",
      "# ChIP-seq file = ['data/GSM2576968_CS17-12341-H3K27me3_sorted.bam']\n",
      "# control file = ['data/CS17-12341-Input_sorted.bam']\n",
      "# effective genome size = 2.70e+09\n",
      "# band width = 300\n",
      "# model fold = [5, 50]\n",
      "# qvalue cutoff = 1.00e-02\n",
      "# The maximum gap between significant sites is assigned as the read length/tag size.\n",
      "# The minimum length of peaks is assigned as the predicted fragment length \"d\".\n",
      "# Larger dataset will be scaled towards smaller dataset.\n",
      "# Range for calculating regional lambda is: 1000 bps and 10000 bps\n",
      "# Broad region calling is off\n",
      "# Paired-End mode is off\n",
      " \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:38: #1 read tag files... \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:38: #1 read treatment tags... \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:39:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:40:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:41:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:41:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:42:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:43:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:44:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:44:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:45:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:46:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:47:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:48:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:48:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:49:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:50:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:51:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:52:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:52:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:53: 18752349 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:53: #1.2 read input tags... \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:54:  1000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:55:  2000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:56:  3000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:56:  4000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:57:  5000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:58:  6000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:36:59:  7000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:00:  8000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:00:  9000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:01:  10000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:02:  11000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:03:  12000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:03:  13000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:04:  14000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:05:  15000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:06:  16000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:07:  17000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:07:  18000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:08:  19000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:09:  20000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:10:  21000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:11:  22000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:11:  23000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:12:  24000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:13:  25000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:14:  26000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:15:  27000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:15:  28000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:16:  29000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:17:  30000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:18:  31000000 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:18: 31524997 reads have been read. \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:18: #1 tag size is determined as 0 bps \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:18: #1 tag size = 0.0 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:18: #1  total tags in treatment: 18752349 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:18: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:18: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:19: #1  tags after filtering in treatment: 9878551 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:19: #1  Redundant rate of treatment: 0.47 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:19: #1  total tags in control: 31524997 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:19: #1 user defined the maximum tags... \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:19: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:19: #1  tags after filtering in control: 28262820 \n",
      "INFO  @ Tue, 17 Feb 2026 20:37:19: #1  Redundant rate of control: 0.10 \n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "conda run -n chip_seq bash -c '\n",
    "samples=(\n",
    "    \"GSM2576895 CS13-12383 H3K4me1\"\n",
    "    \"GSM2576896 CS13-12690 H3K4me1\"\n",
    "    \"GSM2576897 CS13-12829 H3K4me1\"\n",
    "    \"GSM2576898 CS13-12830 H3K4me1\"\n",
    "    \"GSM2576899 CS13-12877 H3K4me1\"\n",
    "    \"GSM2576900 CS14-12408 H3K4me1\"\n",
    "    \"GSM2576901 CS14-12709 H3K4me1\"\n",
    "    \"GSM2576902 CS14-12913 H3K4me1\"\n",
    "    \"GSM2576903 CS15-13000 H3K4me1\"\n",
    "    \"GSM2576904 CS15-13019 H3K4me1\"\n",
    "    \"GSM2576905 CS15-13128 H3K4me1\"\n",
    "    \"GSM2576906 CS17-12331 H3K4me1\"\n",
    "    \"GSM2576907 CS17-12341 H3K4me1\"\n",
    "    \"GSM2576908 CS17-12611 H3K4me1\"\n",
    "    \"GSM2576909 CS13-12383 H3K4me2\"\n",
    "    \"GSM2576910 CS13-12690 H3K4me2\"\n",
    "    \"GSM2576911 CS13-12829 H3K4me2\"\n",
    "    \"GSM2576912 CS13-12830 H3K4me2\"\n",
    "    \"GSM2576913 CS13-12877 H3K4me2\"\n",
    "    \"GSM2576914 CS14-12408 H3K4me2\"\n",
    "    \"GSM2576915 CS14-12709 H3K4me2\"\n",
    "    \"GSM2576916 CS14-12913 H3K4me2\"\n",
    "    \"GSM2576917 CS15-13000 H3K4me2\"\n",
    "    \"GSM2576918 CS15-13019 H3K4me2\"\n",
    "    \"GSM2576919 CS15-13128 H3K4me2\"\n",
    "    \"GSM2576920 CS17-12191 H3K4me2\"\n",
    "    \"GSM2576921 CS17-12331 H3K4me2\"\n",
    "    \"GSM2576922 CS17-12341 H3K4me2\"\n",
    "    \"GSM2576923 CS17-12611 H3K4me2\"\n",
    "    \"GSM2576924 CS20-12104 H3K4me2\"\n",
    "    \"GSM2576925 CS13-12383 H3K4me3\"\n",
    "    \"GSM2576926 CS13-12690 H3K4me3\"\n",
    "    \"GSM2576927 CS13-12829 H3K4me3\"\n",
    "    \"GSM2576928 CS13-12830 H3K4me3\"\n",
    "    \"GSM2576929 CS13-12877 H3K4me3\"\n",
    "    \"GSM2576930 CS14-12408 H3K4me3\"\n",
    "    \"GSM2576931 CS14-12709 H3K4me3\"\n",
    "    \"GSM2576932 CS14-12913 H3K4me3\"\n",
    "    \"GSM2576933 CS15-13000 H3K4me3\"\n",
    "    \"GSM2576934 CS15-13019 H3K4me3\"\n",
    "    \"GSM2576935 CS15-13128 H3K4me3\"\n",
    "    \"GSM2576936 CS17-12331 H3K4me3\"\n",
    "    \"GSM2576937 CS17-12341 H3K4me3\"\n",
    "    \"GSM2576938 CS17-12611 H3K4me3\"\n",
    "    \"GSM2576939 CS13-12383 H3K27ac\"\n",
    "    \"GSM2576940 CS13-12690 H3K27ac\"\n",
    "    \"GSM2576941 CS13-12829 H3K27ac\"\n",
    "    \"GSM2576942 CS13-12830 H3K27ac\"\n",
    "    \"GSM2576943 CS13-12877 H3K27ac\"\n",
    "    \"GSM2576944 CS14-12408 H3K27ac\"\n",
    "    \"GSM2576945 CS14-12709 H3K27ac\"\n",
    "    \"GSM2576946 CS14-12913 H3K27ac\"\n",
    "    \"GSM2576947 CS15-13000 H3K27ac\"\n",
    "    \"GSM2576948 CS15-13019 H3K27ac\"\n",
    "    \"GSM2576949 CS15-13128 H3K27ac\"\n",
    "    \"GSM2576950 CS17-12191 H3K27ac\"\n",
    "    \"GSM2576951 CS17-12331 H3K27ac\"\n",
    "    \"GSM2576952 CS17-12341 H3K27ac\"\n",
    "    \"GSM2576953 CS17-12611 H3K27ac\"\n",
    "    \"GSM2576954 CS20-12104 H3K27ac\"\n",
    "    \"GSM2576956 CS13-12383 H3K27me3\"\n",
    "    \"GSM2576957 CS13-12690 H3K27me3\"\n",
    "    \"GSM2576958 CS13-12829 H3K27me3\"\n",
    "    \"GSM2576959 CS13-12830 H3K27me3\"\n",
    "    \"GSM2576960 CS13-12877 H3K27me3\"\n",
    "    \"GSM2576961 CS14-12408 H3K27me3\"\n",
    "    \"GSM2576962 CS14-12709 H3K27me3\"\n",
    "    \"GSM2576963 CS14-12913 H3K27me3\"\n",
    "    \"GSM2576964 CS15-13000 H3K27me3\"\n",
    "    \"GSM2576965 CS15-13019 H3K27me3\"\n",
    "    \"GSM2576966 CS15-13128 H3K27me3\"\n",
    "    \"GSM2576967 CS17-12331 H3K27me3\"\n",
    "    \"GSM2576968 CS17-12341 H3K27me3\"\n",
    "    \"GSM2576969 CS17-12611 H3K27me3\"\n",
    "    \"GSM2576970 CS13-12383 H3K36me3\"\n",
    "    \"GSM2576971 CS13-12690 H3K36me3\"\n",
    "    \"GSM2576972 CS13-12829 H3K36me3\"\n",
    "    \"GSM2576973 CS13-12830 H3K36me3\"\n",
    "    \"GSM2576974 CS13-12877 H3K36me3\"\n",
    "    \"GSM2576975 CS14-12408 H3K36me3\"\n",
    "    \"GSM2576976 CS14-12709 H3K36me3\"\n",
    "    \"GSM2576977 CS14-12913 H3K36me3\"\n",
    "    \"GSM2576978 CS15-13000 H3K36me3\"\n",
    "    \"GSM2576979 CS15-13019 H3K36me3\"\n",
    "    \"GSM2576980 CS15-13128 H3K36me3\"\n",
    "    \"GSM2576981 CS17-12331 H3K36me3\"\n",
    "    \"GSM2576982 CS17-12341 H3K36me3\"\n",
    "    \"GSM2576983 CS17-12611 H3K36me3\"\n",
    ")\n",
    "\n",
    "for entry in \"${samples[@]}\"; do\n",
    "    read gsm sample mark <<< \"$entry\"\n",
    "    macs2 callpeak \\\n",
    "        -t data/${gsm}_${sample}-${mark}_sorted.bam \\\n",
    "        -c data/${sample}-Input_sorted.bam \\\n",
    "        -f BAM -g hs -B -n ${sample}-${mark} \\\n",
    "        -q 0.01 \\\n",
    "        --outdir data/\n",
    "done'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca56729d-7301-4b89-b0e3-c2860b4da8d1",
   "metadata": {},
   "source": [
    "## Edit first column for bedtools intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e83b9df-6fff-47c3-a271-da7f43c96626",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# remove \"chr\" prefix in col 1 for later bedtools intersect\n",
    "conda run -n chip_seq bash -c 'for f in data/*_peaks.narrowPeak; do \\\n",
    "    base=$(basename $f .narrowPeak); \\\n",
    "    awk \"{gsub(\\\"chr\\\", \\\"\\\", \\$1); print}\" \"$f\" > data/${base}_col1fixed.bed; done'\n",
    "\n",
    "# convert to tab delimited\n",
    "conda run -n chip_seq bash -c 'for f in data/*_peaks_col1fixed.bed; do \\\n",
    "    base=$(basename $f .bed); \\\n",
    "    sed -e \"s/ /\\t/g\" \"$f\" > data/${base}_tabdelim.bed; done'\n",
    "\n",
    "conda run -n chip_seq bash -c 'rm data/*_peaks_col1fixed.bed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e2129b-f5a4-4c8f-9c38-9fbbc2519a88",
   "metadata": {},
   "source": [
    "## Intersect gwas summary and all ChIP-Seq peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15da113f-5706-4905-a0e4-4b2beda064ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# overlap gwas summary and all ChIP-Seq peaks\n",
    "conda run -n chip_seq bash -c 'for f in data/*_peaks_col1fixed_tabdelim.bed; do \\\n",
    "    base=$(basename $f _peaks_col1fixed_tabdelim.bed); \\\n",
    "    bedtools intersect -wao \\\n",
    "        -a ../snp_array/outputs/GWAS_Summary.bed \\\n",
    "        -b \"$f\" \\\n",
    "        > outputs/gwas_summary_${base}_intersect.bed; done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a2e37c-956c-42e5-89e6-ae4bd2a01d38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
